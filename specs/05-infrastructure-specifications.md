---
title: Infrastructure Specifications
version: 2.1
date_created: 2026-02-17
last_updated: 2026-02-17
owner: TJ Monserrat
tags: [infrastructure, gcp, cloud-run, firebase, firestore, bigquery, looker-studio, vector-search, vertex-ai]
---

## Infrastructure Specifications

### Google Cloud Project

- **Project**: *To be created / named*
- **Primary Region**: `asia-southeast1`
- **Billing**: *Budget to be determined*

---

### Components

#### INFRA-001: Firebase Hosting

**Purpose**: Serve the Nuxt 4 SPA static assets (JS, CSS, images) globally via CDN.

**Configuration**:

- Hosting target: Static assets generated by Nuxt 4 build
- Custom domain: `tjmonsi.com`
- SSL/TLS: Managed by Firebase (automatic)
- Cache headers:
  - HTML files: `Cache-Control: no-cache` (always revalidate)
  - JS/CSS/assets with hash: `Cache-Control: public, max-age=31536000, immutable`
  - Images: `Cache-Control: public, max-age=86400`
- Firebase Functions handles SPA serving (all non-asset routes serve the SPA shell)
- **Rewrite rules** (`firebase.json`):
  - `/sitemap.xml` SHALL be rewritten to the Cloud Run backend service to proxy `tjmonsi.com/sitemap.xml` → `GET /sitemap.xml` on the backend API.

  ```json
  {
    "hosting": {
      "rewrites": [
        {
          "source": "/sitemap.xml",
          "run": {
            "serviceId": "<cloud-run-service-name>",
            "region": "asia-southeast1"
          }
        }
      ]
    }
  }
  ```

  - This ensures the sitemap URL declared in `robots.txt` (`https://tjmonsi.com/sitemap.xml`) is accessible on the frontend domain while being served by the backend.

---

#### INFRA-002: Firebase Functions

**Purpose**: Serve the Nuxt 4 SPA shell. When Nuxt 4 is deployed in SPA mode on Firebase Hosting, Firebase Functions is required to serve the SPA while Firebase Hosting serves the static JS/CSS assets.

**Reference**: https://nuxt.com/deploy/firebase

**Configuration**:

- Function runtime: Node.js (as required by Nuxt/Nitro)
- Region: `asia-southeast1` (same as Cloud Run for consistency)
- Purpose: Serve the SPA `index.html` shell for all client-side routes
- Memory: 256 MB (minimal, only serving static HTML)
- Max instances: Auto-scaled by Firebase

---

#### INFRA-003: Google Cloud Run

**Purpose**: Host the Go backend API.

**Configuration**:

| Setting              | Value                           |
| -------------------- | ------------------------------- |
| Container runtime    | Go binary in minimal Docker image |
| Region               | `asia-southeast1`               |
| Min instances        | 0 (scale to zero)               |
| Max instances        | *TBD based on budget*           |
| CPU                  | 1 vCPU (initial)                |
| Memory               | 256 MB (initial)                |
| Concurrency          | 80 (default)                    |
| Request timeout      | 30 seconds                      |
| Startup CPU boost    | Enabled                         |
| Ingress              | Internal + Cloud Load Balancing |
| VPC connector        | Connected to `personal-website-vpc` (see INFRA-009) — Production only. Development environment does NOT use a VPC. |

**Docker Image**:

```dockerfile
# Multi-stage build
FROM golang:1.23-alpine AS builder
WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -o server .

FROM gcr.io/distroless/static-debian12
COPY --from=builder /app/server /server
EXPOSE 8080
ENTRYPOINT ["/server"]
```

**Health Check**: `GET /health` (returns `200` with `{"status": "ok"}`)

---

#### INFRA-004: Google Cloud Load Balancer

**Purpose**: Route traffic, SSL termination, and integration with Cloud Armor.

**Configuration**:

- Type: External Application Load Balancer (Global)
- Backend services:
  - Firebase Hosting (frontend)
  - Cloud Run (backend API)
- SSL Certificate: Google-managed
- URL Map routing:
  - `api.tjmonsi.com/*` → Cloud Run backend
  - `tjmonsi.com/*` → Firebase Hosting + Functions
- Subdomain routing is used to separate frontend and backend traffic.

---

#### INFRA-005: Google Cloud Armor

**Purpose**: WAF and DDoS protection.

**Policies**:

| Rule Priority | Description                              | Action    |
| ------------- | ---------------------------------------- | --------- |
| 500           | Block public access to `/health`         | Deny (403)|
| 1000          | Block known malicious IP ranges          | Deny      |
| 2000          | Rate limiting (60 req/min per IP)        | Throttle  |
| 3000          | Block SQL injection patterns             | Deny      |
| 4000          | Block XSS patterns                       | Deny      |
| 5000          | Block path traversal attempts            | Deny      |
| 9999          | Default allow                            | Allow     |

**Rate Limiting at Cloud Armor level**:

- **Primary rate limiting enforcement**: Cloud Armor handles per-IP rate limiting at the load balancer level. This eliminates the need for application-level in-memory rate counters, which would not persist across Cloud Run instance scaling events.
- **Single rate limit tier**: 60 requests per minute per IP for all clients and all endpoints. No differentiation between user types, bot detection tiers, or endpoint-specific limits.
- Action: HTTP `429` response with `Retry-After` header when limits are exceeded.
- **Progressive banning**: Offender records and ban state are stored in Firestore (`rate_limit_offenders` collection, DM-009). The Go application checks Firestore for ban status on each request and enforces progressive banning logic (see SEC-002 in [06-security-specifications.md](06-security-specifications.md)).
- Note: Cloud Armor provides the rate limiting layer; the application reads offender state from Firestore to enforce progressive banning tiers (429 → 403 → 404).

**Adaptive Protection**:

- Cloud Armor Adaptive Protection SHALL be enabled to provide automatic, ML-based escalating DDoS mitigation.
- Adaptive Protection complements the manual rate-limiting rules by automatically detecting and mitigating L7 DDoS attacks without manual rule updates.
- Reference: [Cloud Armor Adaptive Protection](https://cloud.google.com/armor/docs/adaptive-protection-overview)

**Custom Error Response for 429**:

- Cloud Armor SHALL be configured with a [custom error response](https://cloud.google.com/armor/docs/custom-error-responses) for HTTP 429 status codes.
- The custom error response SHALL return `Content-Type: application/json` with the following body:

```json
{
  "error": "Too many requests. Please try again later.",
  "retry_after": 30
}
```

- Note: Even with this custom error response configured, the frontend (FE-COMP-003) matches 429 responses by status code only and does not depend on the response body format.

---

#### INFRA-006: Database

**Technology**: Firestore Enterprise in MongoDB compatibility mode

**References**:
- Firestore Enterprise: https://firebase.google.com/docs/firestore/enterprise/overview-enterprise-edition-modes
- MongoDB Compatibility Mode: https://firebase.google.com/docs/firestore/enterprise/mongodb-compatibility-overview

| Setting          | Value                              |
| ---------------- | ---------------------------------- |
| Mode             | MongoDB compatibility              |
| Region           | `asia-southeast1`                  |
| Driver           | MongoDB Go driver (standard wire protocol) |
| Security         | Backend-only access (no direct client access) |
| Network access   | Private endpoint or IP allowlist from Cloud Run |
| Backup           | Enabled (managed by Firestore Enterprise) |

---

#### INFRA-007: Google Cloud Logging & Monitoring

**Purpose**: Centralized observability.

**Configuration**:

- **Structured logging** from Cloud Run (JSON format)
- **Log sinks**: Route error logs to a dedicated log bucket with 90-day retention
- **BigQuery log sinks**: Route logs to BigQuery dataset for long-term analytics and SQL querying (see INFRA-010)
- **Alerts**:
  - Error rate > 1% of requests over 5 minutes
  - Latency P95 > 2 seconds over 5 minutes
  - Cloud Run instance memory > 80%
  - Any masked 500 error logged
- **Dashboards**: Request rate, latency, error rate, Cloud Run instance count

---

### CI/CD Pipeline

**Tool**: GitHub Actions (assumed, given `.github/` directory exists)

**Pipeline stages**:

```
┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐
│   Lint   │───▶│   Test   │───▶│  Build   │───▶│  Deploy  │
└──────────┘    └──────────┘    └──────────┘    └──────────┘
```

| Stage   | Frontend                        | Backend                        |
| ------- | ------------------------------- | ------------------------------ |
| Lint    | ESLint, Stylelint               | golangci-lint                  |
| Test    | Vitest (unit), Playwright (E2E) | `go test`                      |
| Build   | `nuxt generate`                 | Docker build                   |
| Deploy  | Firebase deploy                 | Cloud Run deploy               |

**Branch strategy**:
- `main` → Production
- `dev` → Development environment (also used for pre-production validation)
- Feature branches → PR preview (optional)

---

#### INFRA-008: Sitemap Generation (Cloud Function + Cloud Scheduler)

**Purpose**: Periodically regenerate the sitemap and store it in Firestore for serving via the `GET /sitemap.xml` API endpoint.

##### INFRA-008a: Cloud Function — `generate-sitemap`

**Purpose**: Internal Cloud Function that generates the sitemap XML from article data in Firestore.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Function name        | `generate-sitemap`                                 |
| Runtime              | Node.js (Cloud Functions Gen 2)                    |
| Region               | `asia-southeast1`                                  |
| Memory               | 256 MB                                             |
| Timeout              | 60 seconds                                         |
| Trigger              | HTTP (invoked by Cloud Scheduler)                  |
| Ingress              | Internal only (no public access)                   |
| VPC connector        | Connected to the project VPC (see INFRA-009) — Production only |
| Authentication       | Requires authentication (OIDC token from Cloud Scheduler service account) |

**Sitemap Generation Logic**:

1. Query all published articles from `technical_articles` and `blog_articles` collections.
2. Include static pages: `/`, `/technical`, `/blog`, `/socials`, `/others`, `/privacy`.
3. Article URLs SHALL include the `.md` extension (e.g., `https://tjmonsi.com/technical/article-title-2025-01-15-1030.md`).
4. Build sitemap XML per the [Sitemaps protocol](https://www.sitemaps.org/protocol.html).
5. Write the generated XML to the `sitemap` Firestore collection (DM-010).
6. The `GET /sitemap.xml` public endpoint reads from this collection (BE-API-011).

##### INFRA-008b: Cloud Scheduler — `trigger-sitemap-generation`

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Job name             | `trigger-sitemap-generation`                       |
| Schedule             | Every 6 hours (`0 */6 * * *`)                      |
| Target               | Cloud Function `generate-sitemap` (HTTP trigger)   |
| HTTP method          | POST                                               |
| Authentication       | OIDC token (service account with Cloud Functions invoker role) |
| Region               | `asia-southeast1`                                  |
| Retry config         | Max 3 retries with exponential backoff             |

**Notes**:
- The Cloud Function runs internally only and is NOT accessible from the public internet.
- The 6-hour schedule balances freshness with cost. Adjust based on content update frequency.

---

##### INFRA-008c: Cloud Function — `process-rate-limit-logs`

**Purpose**: Process Cloud Armor rate-limit (429) log entries via a log sink and write offense records to the `rate_limit_offenders` Firestore collection (DM-009). This bridges the gap between Cloud Armor's request-level rate limiting and the application's progressive banning logic — Cloud Armor blocks requests before they reach Cloud Run, so the Go application cannot directly observe rate-limited requests.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Function name        | `process-rate-limit-logs`                          |
| Runtime              | Node.js (Cloud Functions Gen 2)                    |
| Region               | `asia-southeast1`                                  |
| Memory               | 256 MB                                             |
| Timeout              | 60 seconds                                         |
| Trigger              | Cloud Logging log sink (via Pub/Sub)               |
| Ingress              | Internal only (no public access)                   |
| VPC connector        | Connected to the project VPC (see INFRA-009) — Production only |
| Authentication       | Service account with Firestore read/write access   |

**Log Sink Configuration**:

- A Cloud Logging log sink SHALL be configured to route Cloud Armor rate-limit events to a Pub/Sub topic.
- Log sink filter: Cloud Armor logs where the response status is `429` (rate limit exceeded).
- The Pub/Sub topic triggers the `process-rate-limit-logs` Cloud Function.

**Processing Logic**:

1. Receive Cloud Armor log entry from Pub/Sub.
2. Extract the client IP address from the log entry.
3. Look up or create the offender record in the `rate_limit_offenders` collection (DM-009) by client IP.
4. Increment `offense_count` and append to `offense_history`.
5. Evaluate progressive banning thresholds (see SEC-002 in [06-security-specifications.md](06-security-specifications.md)):
   - 5 offenses within 7 days → set 30-day ban.
   - 2 offenses after 30-day ban expires → set 90-day ban.
   - 2 offenses after 90-day ban expires → set indefinite ban.
6. Write updated record to Firestore.

**Notes**:
- The Cloud Function runs internally only and is NOT accessible from the public internet.
- The Go application (Cloud Run) reads DM-009 on each incoming request to check ban status and enforce the appropriate response code (403 or 404).

---

#### INFRA-009: VPC Network (Production Only)

**Purpose**: Provide private networking for Cloud Run and Cloud Functions in the **Production** environment, restricting egress to Google Cloud APIs only. The Development environment does NOT use a VPC to reduce cost; services connect to Google Cloud APIs directly.

**Configuration**:

| Setting                  | Value                                              |
| ------------------------ | -------------------------------------------------- |
| VPC name                 | `personal-website-vpc`                             |
| Region                   | `asia-southeast1`                                  |
| Subnet (Cloud Run)       | Minimum subnet (e.g., `/28`) for Cloud Run VPC connector |
| Subnet (Cloud Functions) | Minimum subnet (e.g., `/28`) for Cloud Functions VPC connector |
| Private Google Access    | Enabled (allows access to Google Cloud APIs without public IPs) |
| NAT                      | None (no Cloud NAT router)                         |
| Firewall rules           | Default deny egress to internet; allow egress to Google Cloud API ranges only |

**VPC Connectors**:

- **Cloud Run VPC connector**: Connects the Go backend API (INFRA-003) to the VPC. Enables private access to Firestore Enterprise and other Google Cloud services.
- **Cloud Functions VPC connector**: Connects the sitemap generation Cloud Function (INFRA-008a) and the log processing Cloud Function (INFRA-008c) to the VPC. Enables private access to Firestore Enterprise.

**Network Policy**:

- Cloud Run and Cloud Functions SHALL route all egress traffic through the VPC in **Production**.
- Egress SHALL be restricted to Google Cloud API endpoints only (via Private Google Access).
- No outbound internet access is required — all external dependencies are Google Cloud services.
- No Cloud NAT router is provisioned to minimize cost and attack surface.
- In **Development**, no VPC is provisioned. Services connect to Google Cloud APIs directly to reduce cost.

---

#### INFRA-012: Firestore Native Mode Instance (Vector Search)

**Purpose**: Provide a Firestore Native Mode database for vector similarity search on article embeddings. This is separate from the Firestore Enterprise instance (MongoDB compat mode) used for application data.

**Configuration**:

| Setting                  | Value                                              |
| ------------------------ | -------------------------------------------------- |
| Database mode            | Firestore Native Mode                              |
| Database ID              | `vector-search` (named database, not `(default)`)  |
| Region                   | `asia-southeast1`                                  |
| Collections              | `technical_article_vectors`, `blog_article_vectors`, `others_vectors` |
| Vector indexes           | One per collection on `embedding` field (2048 dimensions, COSINE). 2048 is the maximum embedding dimension supported by Firestore Native. See: https://cloud.google.com/firestore/native/docs/vector-search |

**Vector Index Configuration** (per collection):

```
gcloud firestore indexes composite create \
  --database=vector-search \
  --collection-group=technical_article_vectors \
  --field-config=vector-config='{"dimension":2048,"flat":{}}',field-path=embedding
```

> Repeat for `blog_article_vectors` and `others_vectors`.

**Notes**:
- Firestore Native Mode is required for vector search (`findNearest()` API). Firestore Enterprise in MongoDB compat mode does not support native vector search.
- Both Firestore instances coexist in the same GCP project. The default database hosts Firestore Enterprise; the named database (`vector-search`) hosts Firestore Native.
- Reference: https://cloud.google.com/firestore/native/docs/vector-search

---

#### INFRA-013: Vertex AI — Gemini Embedding API

**Purpose**: Generate text embeddings using the Gemini `gemini-embedding-001` model via Vertex AI for semantic search.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| API                  | Vertex AI Embeddings API (`predict`)               |
| Model                | `gemini-embedding-001`                             |
| Region               | `asia-southeast1`                                  |
| Output dimensions    | 2048 (via `output_dimensionality` parameter; default is 3072; 2048 is Firestore Native max) |
| Task type            | `RETRIEVAL_DOCUMENT` (used for both document indexing and search queries) |
| Normalization        | L2-normalize all 2048-dimensional vectors before storage (required for non-3072 dimensions) |
| Authentication       | IAM — service accounts with `roles/aiplatform.user` |

**API Endpoint**:
```
POST https://asia-southeast1-aiplatform.googleapis.com/v1/projects/{project}/locations/asia-southeast1/publishers/google/models/gemini-embedding-001:predict
```

**Usage**:

| Caller                                | Task Type            | Purpose                                    |
| ------------------------------------- | -------------------- | ------------------------------------------ |
| Cloud Run (Go API)                    | `RETRIEVAL_DOCUMENT` | Embed search queries on cache miss         |
| `sync-article-embeddings` (INFRA-014) | `RETRIEVAL_DOCUMENT` | Embed article content during sync          |

**Cost Considerations**:
- Pricing: per 1,000 characters of input text. See: https://cloud.google.com/vertex-ai/generative-ai/pricing
- The embedding cache (DM-011) eliminates redundant API calls for repeated search queries.
- Article embeddings are generated once per content change (not per request).

**Normalization Note**:
- The `gemini-embedding-001` model produces normalized embeddings at 3072 dimensions only. When using `output_dimensionality=2048`, the truncated embedding MUST be L2-normalized (divide each component by the L2 norm of the vector) before storage and comparison.

**Reference**: https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings

---

#### INFRA-014: Cloud Function — `sync-article-embeddings`

**Purpose**: Generate and synchronize article embedding vectors from Firestore Enterprise to Firestore Native Mode. Called by the content management CI/CD pipeline after articles are pushed to Firestore Enterprise.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Function name        | `sync-article-embeddings`                          |
| Runtime              | Node.js (Cloud Functions Gen 2)                    |
| Region               | `asia-southeast1`                                  |
| Memory               | 512 MB                                             |
| Timeout              | 300 seconds (5 minutes)                            |
| Trigger              | HTTP (invoked by content CI/CD pipeline)            |
| Ingress              | Internal only (no public access)                   |
| VPC connector        | Connected to the project VPC (see INFRA-009) — Production only |
| Authentication       | Requires authentication (service account with appropriate roles) |

**Sync Logic**:

1. Read all articles from `technical_articles`, `blog_articles`, and `others` collections in Firestore Enterprise (via MongoDB driver or admin SDK).
2. For each article, construct the embedding source text: `title + "\n" + abstract + "\n" + category + "\n" + tags (comma-separated)`.
3. Compute SHA-256 hash of the source text.
4. Compare the hash with the `embedding_text_hash` field in the corresponding Firestore Native document.
   - **If unchanged**: Skip (no re-embedding needed).
   - **If changed or new**: Call Vertex AI Gemini `gemini-embedding-001` API with `task_type=RETRIEVAL_DOCUMENT` and `output_dimensionality=2048` to generate a 2048-dimensional embedding vector. L2-normalize the vector before writing to Firestore Native.
5. Write/update the vector document in the appropriate Firestore Native collection (`technical_article_vectors`, `blog_article_vectors`, or `others_vectors`).
6. Delete vector documents from Firestore Native that no longer have corresponding articles in Firestore Enterprise (orphan cleanup).

**Notes**:
- This function is idempotent. Running it multiple times produces the same result.
- The hash-based change detection avoids unnecessary Gemini API calls, reducing cost.
- The content CI/CD pipeline SHOULD call this function after successfully pushing content to Firestore Enterprise.
- The function MAY also be triggered by Cloud Scheduler as a periodic safety net (e.g., daily) to catch any missed syncs.

---

#### INFRA-010: BigQuery Analytics Dataset & Log Sinks

**Purpose**: Route Cloud Logging logs to BigQuery for long-term storage, SQL-based analytics, and integration with Looker Studio dashboards.

**Dataset Configuration**:

| Setting              | Value                              |
| -------------------- | ---------------------------------- |
| Dataset name         | `website_logs`                     |
| Region               | `asia-southeast1`                  |
| Default table expiry | 730 days (2 years)                 |

**Log Sinks**:

Five Cloud Logging log sinks route logs to dedicated BigQuery tables within the `website_logs` dataset:

##### INFRA-010a: All Logs

| Setting          | Value                                              |
| ---------------- | -------------------------------------------------- |
| Sink name        | `sink-all-logs`                                    |
| Destination      | BigQuery table `website_logs.all_logs`              |
| Filter           | *(no filter — captures all project logs)*          |
| Purpose          | Complete log archive for ad-hoc SQL analysis       |

##### INFRA-010b: Cloud Armor & Load Balancer Logs

| Setting          | Value                                              |
| ---------------- | -------------------------------------------------- |
| Sink name        | `sink-cloud-armor-lb`                              |
| Destination      | BigQuery table `website_logs.cloud_armor_lb_logs`  |
| Filter           | `resource.type="http_load_balancer"`               |
| Purpose          | WAF events, rate limiting analysis, traffic patterns |

##### INFRA-010c: Frontend Error Logs

| Setting          | Value                                              |
| ---------------- | -------------------------------------------------- |
| Sink name        | `sink-frontend-errors`                             |
| Destination      | BigQuery table `website_logs.frontend_error_logs`  |
| Filter           | `resource.type="cloud_run_revision" AND jsonPayload.log_type="frontend_error"` |
| Purpose          | Client-side error trend analysis, browser/connection correlation |

**Note**: Requires the Go backend to emit a `log_type: "frontend_error"` field in structured log entries when processing `POST /t` requests with `action: "error_report"` (see OBS-001 in [07-observability-specifications.md](07-observability-specifications.md)).

##### INFRA-010d: Backend Error Logs

| Setting          | Value                                              |
| ---------------- | -------------------------------------------------- |
| Sink name        | `sink-backend-errors`                              |
| Destination      | BigQuery table `website_logs.backend_error_logs`   |
| Filter           | `resource.type="cloud_run_revision" AND severity>=ERROR AND NOT jsonPayload.log_type="frontend_error"` |
| Purpose          | Backend error trend analysis, masked 500 tracking  |

##### INFRA-010e: Frontend Tracking Logs

| Setting          | Value                                              |
| ---------------- | -------------------------------------------------- |
| Sink name        | `sink-frontend-tracking`                           |
| Destination      | BigQuery table `website_logs.frontend_tracking_logs` |
| Filter           | `resource.type="cloud_run_revision" AND jsonPayload.log_type="frontend_tracking"` |
| Purpose          | Visitor analytics — unique visitors, page views, referrer sources, browser distribution |

**Note**: Requires the Go backend to emit a `log_type: "frontend_tracking"` field in structured log entries when processing `POST /t` requests with `action: "page_view"` or other tracking actions (see OBS-001 in [07-observability-specifications.md](07-observability-specifications.md)).

**BigQuery Table Schema**:

- All tables use the [Cloud Logging BigQuery schema](https://cloud.google.com/logging/docs/export/bigquery) automatically generated by the log sink export.
- Key queryable fields in the auto-generated schema:
  - `timestamp` — log entry timestamp
  - `severity` — log severity level
  - `jsonPayload` — structured log data (RECORD type, fields vary by log entry)
  - `resource` — resource metadata (type, labels)
  - `httpRequest` — HTTP request details (for load balancer logs)

**Data Retention**:

- All tables in the `website_logs` dataset SHALL have a default table expiry of **730 days (2 years)**. Data older than 2 years is automatically deleted by BigQuery.
- This 2-year retention applies uniformly to all 5 tables. No table retains data indefinitely.
- The retention period balances long-term trend analysis with privacy obligations and cost management.

**Data Anonymization in BigQuery**:

- IP addresses exported to BigQuery via Cloud Logging log sinks are the same values logged by the Go backend. The Go backend SHALL truncate IPv4 addresses (zero the last octet, e.g., `203.0.113.0`) and truncate IPv6 addresses (zero the last 80 bits) **before** writing log entries. This ensures that no full IP addresses are stored in BigQuery.
- User-Agent strings exported to BigQuery contain browser name and version only (as sent by the frontend in the `POST /t` request body). Raw `User-Agent` headers from `httpRequest` fields in load balancer logs (`cloud_armor_lb_logs`) are retained as-is since they do not contain personally identifiable information beyond general browser/OS info.
- No cookies, user accounts, session identifiers, or device fingerprints are present in any BigQuery table.
- The `frontend_tracking_logs` and `frontend_error_logs` tables contain only the structured fields emitted by the Go backend when processing `POST /t` requests (see OBS-001, OBS-002, OBS-003 in [07-observability-specifications.md](07-observability-specifications.md)).

**Summary of Data Stored in BigQuery**:

| Table                     | Personal Data Present                         | Anonymization Applied                  | Retention |
| ------------------------- | --------------------------------------------- | -------------------------------------- | --------- |
| `all_logs`                | Truncated IP addresses                        | IP last octet zeroed                   | 2 years   |
| `cloud_armor_lb_logs`     | Truncated IP, User-Agent (browser/OS info)    | IP last octet zeroed by Cloud Armor config | 2 years |
| `frontend_error_logs`     | Truncated IP, browser name/version            | IP last octet zeroed                   | 2 years   |
| `backend_error_logs`      | Truncated IP (in request context)             | IP last octet zeroed                   | 2 years   |
| `frontend_tracking_logs`  | Truncated IP, browser, referrer, page visited | IP last octet zeroed                   | 2 years   |

**Notes**:
- Log sinks operate independently of the existing Cloud Logging log buckets and the rate-limit log sink (INFRA-008c). They do not interfere with each other.
- BigQuery tables are partitioned by ingestion time automatically when created by log sinks.
- The 2-year table expiry is set at the dataset level as the default. Individual tables inherit this expiry unless explicitly overridden (which SHALL NOT be done).

---

#### INFRA-011: Looker Studio Integration

**Purpose**: Provide owner-operated analytics dashboards using Looker Studio connected to the BigQuery `website_logs` dataset.

**Service Account Configuration**:

| Setting                    | Value                                              |
| -------------------------- | -------------------------------------------------- |
| Service account name       | `looker-studio-reader`                             |
| Service account email      | `looker-studio-reader@<project-id>.iam.gserviceaccount.com` |
| BigQuery role (dataset)    | `roles/bigquery.dataViewer` on `website_logs` dataset |
| BigQuery role (project)    | `roles/bigquery.jobUser` on project (required to run queries) |
| Key type                   | Service account key (JSON) for Looker Studio data connector |

**Looker Studio Configuration**:

| Setting                    | Value                                              |
| -------------------------- | -------------------------------------------------- |
| Data source type           | BigQuery connector                                 |
| Authentication             | Service account (JSON key)                         |
| Tables connected           | All 5 tables in `website_logs` dataset             |
| Refresh schedule           | Automatic (Looker Studio default)                  |

**Analytics Capabilities**:

The following analytics are enabled by the BigQuery data via Looker Studio:

| Metric / Report              | Source Table                    | Description                                    |
| ---------------------------- | ------------------------------- | ---------------------------------------------- |
| Unique visitors              | `frontend_tracking_logs`        | Distinct IP addresses per time period          |
| Page views over time         | `frontend_tracking_logs`        | Total and per-page view counts                 |
| Top pages by visits          | `frontend_tracking_logs`        | Most visited pages ranked                      |
| Referrer sources             | `frontend_tracking_logs`        | Traffic sources breakdown                      |
| Browser distribution         | `frontend_tracking_logs`        | Browser name/version breakdown                 |
| Geographic distribution      | `frontend_tracking_logs`        | Visitor locations derived from IP              |
| Connection speed analysis    | `frontend_tracking_logs`        | Visitor connection quality breakdown           |
| Frontend error trends        | `frontend_error_logs`           | Error frequency, types, and affected pages     |
| Error-browser correlation    | `frontend_error_logs`           | Errors grouped by browser/connection speed     |
| Backend error trends         | `backend_error_logs`            | Backend error frequency and types              |
| Masked 500 tracking          | `backend_error_logs`            | Internal errors masked as 404                  |
| Cloud Armor activity         | `cloud_armor_lb_logs`           | Rate limit blocks, WAF events over time        |
| Traffic patterns             | `cloud_armor_lb_logs`           | Request volume, geographic distribution        |
| Request latency analysis     | `all_logs`                      | API latency percentiles from structured logs   |

**Notes**:
- Looker Studio is owned and operated by the website owner. No public access.
- The service account has read-only access — it cannot modify or delete data.
- Looker Studio queries against BigQuery may incur costs based on the amount of data scanned. Use partitioned tables and targeted queries to minimize costs.

---

### Network Diagram

```
                    Internet
                       │
                       ▼
              ┌─────────────────┐
              │   Cloud DNS     │
              │  tjmonsi.com    │
              │ api.tjmonsi.com │
              └────────┬────────┘
                       │
                       ▼
              ┌─────────────────┐
              │  Cloud Armor    │
              │  (WAF / DDoS)   │
              └────────┬────────┘
                       │
                       ▼
              ┌─────────────────┐
              │  Cloud Load     │
              │  Balancer (L7)  │
              └───┬─────────┬───┘
                  │         │
        ┌─────────┘         └─────────┐
        ▼                             ▼
┌───────────────┐       ┌──── VPC (Production only) ────┐
│   Firebase    │       │                                │
│   Hosting +   │       │  ┌───────────────┐             │
│   Functions   │       │  │   Cloud Run   │             │
│   (SPA)       │       │  │   (Go API)    │             │
│               │       │  │   0-N inst.   │             │
│  Rewrites:    │       │  └───────┬───────┘             │
│  /sitemap.xml─│───────│──────────┘                     │
└───────────────┘       │          │                      │
                        │          ▼                      │
                        │  ┌───────────────┐             │
                        │  │   Firestore   │             │
                        │  │   Enterprise  │             │
                        │  │   asia-se1    │             │
                        │  └───────┬───────┘             │
                        │          ▲                      │
                        │  ┌───────┴───────┐             │
Cloud Scheduler ───────▶│  │Cloud Function │             │
                        │  │(Sitemap Gen)  │             │
                        │  └───────────────┘             │
                        │                                │
                        │  ┌───────────────┐             │
Cloud Armor Log Sink ──▶│  │Cloud Function │             │
                        │  │(Log Proc.)    │             │
                        │  └───────────────┘             │
                        │                                │
                        │  ┌───────────────┐             │
Content CI/CD ─────────▶│  │Cloud Function │             │
                        │  │(Embed Sync)   │             │
                        │  └───────┬───────┘             │
                        └──────────│─────────────────────┘
                                   │
                        ┌──────────▼─────────────────────┐
                        │   Firestore Native Mode        │
                        │   (Vector Search)              │
                        │   asia-southeast1              │
                        └────────────────────────────────┘
                                   ▲
                        Cloud Run + Embed Sync
                        query/write vectors
                        ┌────────────────────────────────┐
                        │   Vertex AI (Gemini)           │
                        │   gemini-embedding-001          │
                        └────────────────────────────────┘
                                   ▲
                        Cloud Run + Embed Sync
                        call for embeddings

              Cloud Logging (receives all service logs)
                           │
                           ▼ (5 Log Sinks)
              ┌──────────────────────────────────┐
              │           BigQuery               │
              │    Dataset: website_logs          │
              │                                  │
              │  • all_logs                      │
              │  • cloud_armor_lb_logs           │
              │  • frontend_error_logs           │
              │  • backend_error_logs            │
              │  • frontend_tracking_logs        │
              └────────────┬─────────────────────┘
                           │ (Service Account)
                           ▼
              ┌──────────────────────────────────┐
              │        Looker Studio             │
              │   (Owner-operated analytics)     │
              └──────────────────────────────────┘
```
