---
title: Infrastructure Specifications
version: 4.0
date_created: 2026-02-17
last_updated: 2026-02-20
owner: TJ Monserrat
tags: [infrastructure, gcp, cloud-run, firebase, firestore, bigquery, looker-studio, vector-search, vertex-ai, terraform, iac, artifact-registry, cloud-dns, pubsub]
---

## Infrastructure Specifications

### Google Cloud Project

- **Project ID**: `<project-id>` *(obfuscated — the GCP project already exists)*
- **Primary Region**: `asia-southeast1`
- **Billing**: Linked to billing account

> **Note**: The project ID is obfuscated in this documentation because it may be shared publicly for teaching purposes. Exposing the project ID could be an attack vector (e.g., targeted API abuse, resource enumeration). Replace `<project-id>` with the actual project ID in deployment configurations.

---

### Components

#### INFRA-001: Firebase Hosting

**Purpose**: Serve the Nuxt 4 SPA static assets (JS, CSS, images) globally via CDN.

**Configuration**:

- Hosting target: Static assets generated by Nuxt 4 build
- Custom domain: `tjmonsi.com`
- SSL/TLS: Managed by Firebase (automatic)
- Cache headers:
  - HTML files: `Cache-Control: no-cache` (always revalidate)
  - JS/CSS/assets with hash: `Cache-Control: public, max-age=31536000, immutable`
  - Images: `Cache-Control: public, max-age=86400`
- Firebase Functions handles SPA serving (all non-asset routes serve the SPA shell)
- **Rewrite rules** (`firebase.json`):
  - `/sitemap.xml` SHALL be rewritten to the Cloud Run backend service to proxy `tjmonsi.com/sitemap.xml` → `GET /sitemap.xml` on the backend API.

  ```json
  {
    "hosting": {
      "rewrites": [
        {
          "source": "/sitemap.xml",
          "run": {
            "serviceId": "website-api",
            "region": "asia-southeast1"
          }
        }
      ]
    }
  }
  ```

  - This ensures the sitemap URL declared in `robots.txt` (`https://tjmonsi.com/sitemap.xml`) is accessible on the frontend domain while being served by the backend.

---

#### INFRA-002: Firebase Functions

**Purpose**: Serve the Nuxt 4 SPA shell. When Nuxt 4 is deployed in SPA mode on Firebase Hosting, Firebase Functions is required to serve the SPA while Firebase Hosting serves the static JS/CSS assets.

**Reference**: https://nuxt.com/deploy/firebase

**Configuration**:

- Function runtime: Node.js 22 LTS (as required by Nuxt/Nitro) (CLR-135)
- Region: `asia-southeast1` (same as Cloud Run for consistency)
- Purpose: Serve the SPA `index.html` shell for all client-side routes
- Memory: 256 MB (minimal, only serving static HTML)
- Max instances: Auto-scaled by Firebase

---

#### INFRA-003: Google Cloud Run

**Purpose**: Host the Go backend API.

**Configuration**:

| Setting              | Value                           |
| -------------------- | ------------------------------- |
| Container runtime    | Go binary in minimal Docker image |
| Region               | `asia-southeast1`               |
| Min instances        | 0 (scale to zero)               |
| Max instances        | 5                               |
| CPU                  | 1 vCPU                          |
| Memory               | 1 GB                            |
| Concurrency          | 160                             |
| Request timeout      | 30 seconds                      |
| Startup CPU boost    | Enabled                         |
| Service name         | `website-api` (illustrative; may be adjusted during implementation) (CLR-147) |
| Ingress              | Internal + Cloud Load Balancing |
| VPC egress          | Connected to `personal-website-vpc` via **Direct VPC Egress** (see INFRA-009) — Production only. Development environment does NOT use a VPC. |

**Docker Image**:

```dockerfile
# Multi-stage build
FROM golang:1.24-alpine AS builder
# NOTE: Use the latest stable Go version at build time. Update this
# base image when new Go stable releases become available. (CLR-195)
WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -o server .

# Create non-root user 'jack' in builder (distroless has no shell/useradd)
RUN addgroup -S jack && adduser -S -G jack -u 10001 jack

FROM gcr.io/distroless/static-debian12

# Copy passwd/group so the runtime knows about 'jack'
COPY --from=builder /etc/passwd /etc/passwd
COPY --from=builder /etc/group /etc/group

COPY --from=builder /app/server /server

# GeoIP database for country-level resolution from truncated IPs (CLR-133)
COPY GeoLite2-Country.mmdb /data/GeoLite2-Country.mmdb

# Run as non-root user 'jack' — no root credentials or privileges
USER jack:jack

EXPOSE 8080
ENTRYPOINT ["/server"]
```

**GeoIP Database Update** (CLR-151):

- The MaxMind GeoLite2-Country database (`.mmdb`) is `COPY`'d into the Docker image at build time. GeoLite2 databases are updated weekly by MaxMind.
- The Application CI/CD pipeline SHALL download the latest GeoLite2-Country database before the Docker build step, using a MaxMind license key stored in GitHub Actions secrets (secret name: `MAXMIND_LICENSE_KEY`).
- Download URL: `https://download.maxmind.com/app/geoip_download?edition_id=GeoLite2-Country&license_key=${MAXMIND_LICENSE_KEY}&suffix=tar.gz`
- A **weekly scheduled GitHub Actions workflow** SHALL rebuild and redeploy the Docker image with the latest GeoLite2 database, even if no code changes have occurred. This ensures the GeoIP database is refreshed at least weekly.
- The scheduled workflow SHALL use a cron schedule of `0 0 * * 0` (Sunday midnight UTC) in the GitHub Actions workflow file.
- The scheduled workflow SHALL run independently of the main application CI/CD pipeline and SHALL follow the same build-test-deploy stages.

**Container Security**:

- The container SHALL run as the non-root user `jack` (UID 10001). Root credentials and privileges are not present at runtime.
- The `gcr.io/distroless/static-debian12` base image contains no shell, package manager, or unnecessary binaries — reducing the attack surface.
- The `USER jack:jack` directive ensures the process cannot escalate to root.
- Cloud Run SHALL be configured with `--no-allow-unauthenticated` for internal endpoints and `run.googleapis.com/container-security-context: {"runAsNonRoot": true}` annotation where supported.

**Artifact Registry**: Docker images are pushed to Artifact Registry (INFRA-018) by the CI/CD pipeline. Cloud Run pulls images from `asia-southeast1-docker.pkg.dev/<project-id>/website-images/`.

**Health Check**: `GET /health` (returns `200` with `{"status": "ok"}`)

---

#### INFRA-004: Google Cloud Load Balancer

**Purpose**: Route traffic, SSL termination, and integration with Cloud Armor.

**Configuration**:

- Type: External Application Load Balancer (Global)
- Backend services:
  - Firebase Hosting (frontend)
  - Cloud Run (backend API)
- SSL Certificate: Google-managed
- URL Map routing:
  - `api.tjmonsi.com/*` → Cloud Run backend
  - `tjmonsi.com/*` → Firebase Hosting + Functions
- Subdomain routing is used to separate frontend and backend traffic.

> **Note**: The Global External Application Load Balancer automatically provides both IPv4 and IPv6 addresses with a single forwarding rule. No separate forwarding rule is required for IPv6 traffic. AAAA records in INFRA-017 point to the LB's auto-assigned IPv6 address.

---

#### INFRA-005: Google Cloud Armor

**Purpose**: WAF and DDoS protection.

**Policies**:

| Rule Priority | Description                              | Action    |
| ------------- | ---------------------------------------- | --------- |
| 500           | Block public access to `/health`         | Deny (403)|
| 1000          | Block known malicious IP ranges          | Deny      |
| 2000          | Rate limiting (60 req/min per IP)        | Throttle  |
| 3000          | Block SQL injection patterns             | Deny      |
| 4000          | Block XSS patterns                       | Deny      |
| 5000          | Block path traversal attempts            | Deny      |
| 9999          | Default allow                            | Allow     |

> **Note**: Rule 500 is defense-in-depth. Cloud Run's ingress is set to `internal-and-cloud-load-balancing`, meaning direct access is already blocked. Cloud Armor provides an additional layer of filtering at the edge before traffic reaches Cloud Run. (CLR-174)

**Rate Limiting at Cloud Armor level**:

- **Primary rate limiting enforcement**: Cloud Armor handles per-IP rate limiting at the load balancer level. This eliminates the need for application-level in-memory rate counters, which would not persist across Cloud Run instance scaling events.
- **Single rate limit tier**: 60 requests per minute per IP for all clients and all endpoints. No differentiation between user types, bot detection tiers, or endpoint-specific limits.
- Action: HTTP `429` response with `Retry-After` header when limits are exceeded.
- **Progressive banning**: Offender records and ban state are stored in Firestore (`rate_limit_offenders` collection, DM-009). The Go application checks Firestore for ban status on each request and enforces progressive banning logic (see SEC-002 in [06-security-specifications.md](06-security-specifications.md)).
- Note: Cloud Armor provides the rate limiting layer; the application reads offender state from Firestore to enforce progressive banning tiers (429 → 403 → 404).

**Adaptive Protection**:

- Cloud Armor Adaptive Protection SHALL be enabled to provide ML-based DDoS detection with recommended rules that the owner can review and apply.
- Adaptive Protection complements the manual rate-limiting rules by detecting anomalous L7 traffic patterns and generating suggested protective rules. The owner reviews alerts and applies recommended rules as needed.
- This uses **Cloud Armor Standard** tier. Automatic rule deployment (without owner review) requires Cloud Armor Enterprise tier, which is not cost-justified for a personal website.
- Reference: [Cloud Armor Adaptive Protection](https://cloud.google.com/armor/docs/adaptive-protection-overview)

**Custom Error Response for 429**:

- Cloud Armor SHALL be configured with a [custom error response](https://cloud.google.com/armor/docs/custom-error-responses) for HTTP 429 status codes.
- The custom error response SHALL return `Content-Type: application/json` with the following body:

```json
{
  "error": "Too many requests. Please try again later.",
  "retry_after": 30
}
```

- Note: Even with this custom error response configured, the frontend (FE-COMP-003) matches 429 responses by status code only and does not depend on the response body format.

---

#### INFRA-006: Database

**Technology**: Firestore Enterprise in MongoDB compatibility mode

**References**:
- Firestore Enterprise: https://firebase.google.com/docs/firestore/enterprise/overview-enterprise-edition-modes
- MongoDB Compatibility Mode: https://firebase.google.com/docs/firestore/enterprise/mongodb-compatibility-overview

| Setting          | Value                              |
| ---------------- | ---------------------------------- |
| Mode             | MongoDB compatibility              |
| Region           | `asia-southeast1`                  |
| Driver           | MongoDB Go driver (standard wire protocol) |
| Security         | IAM-based authentication via `roles/datastore.user` (no direct client access) |
| Authentication   | IAM service account auth — Cloud Run service account authenticates via connection string using the MongoDB Go driver. See: https://docs.cloud.google.com/firestore/mongodb-compatibility/docs/connect#cloud-run |
| Dev access       | Temporary access token for local development. See: https://docs.cloud.google.com/firestore/mongodb-compatibility/docs/connect#connect_with_a_temporary_access_token |
| Backup           | Enabled (managed by Firestore Enterprise) |

**Connection String Format** (Cloud Run):

```
mongodb+srv://cloud-run-api@<project-id>.iam@<database-id>.<region>.firestore.goog/?authMechanism=MONGODB-OIDC&readPreference=primary
```

Where `<project-id>` is the GCP project ID, `<database-id>` is the Firestore database name, and `<region>` is `asia-southeast1`.

---

#### INFRA-007: Google Cloud Logging & Monitoring

**Purpose**: Centralized observability.

**Configuration**:

- **Structured logging** from Cloud Run (JSON format)
- **Log retention**: Cloud Logging's default `_Default` bucket with retention configured to **90 days**. No dedicated custom log bucket is provisioned — BigQuery log sinks (INFRA-010) handle long-term analytics and the default bucket provides sufficient operational access for debugging and incident response.
- **BigQuery log sinks**: Route logs to BigQuery dataset for long-term analytics and SQL querying (see INFRA-010)
- **Alerts**: See OBS-005 in [07-observability-specifications.md](07-observability-specifications.md) for the complete alerting specification.
- **Dashboards**: See OBS-006 in [07-observability-specifications.md](07-observability-specifications.md) for the dashboard specification.

---

### CI/CD Pipeline

**Tool**: GitHub Actions (assumed, given `.github/` directory exists)

**Pipeline stages (Application)**:

```
┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐
│   Lint   │───▶│   Test   │───▶│  Build   │───▶│  Deploy  │
└──────────┘    └──────────┘    └──────────┘    └──────────┘
```

| Stage   | Frontend                        | Backend                        |
| ------- | ------------------------------- | ------------------------------ |
| Lint    | ESLint, Stylelint               | golangci-lint                  |
| Test    | Vitest (unit), Playwright (E2E) | `go test`                      |
| Build   | `nuxt generate`                 | Docker build                   |
| Deploy  | Firebase deploy                 | Cloud Run deploy               |

**Pipeline stages (Infrastructure — Terraform)**:

```
┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐
│  Format  │───▶│ Validate │───▶│   Plan   │───▶│  Apply   │
└──────────┘    └──────────┘    └──────────┘    └──────────┘
```

| Stage    | Tool / Command       | Notes                                            |
| -------- | -------------------- | ------------------------------------------------ |
| Format   | `terraform fmt`      | Verify formatting consistency                    |
| Validate | `terraform validate` | Syntax and configuration validation              |
| Plan     | `terraform plan`     | Preview changes; output saved as artifact        |
| Apply    | `terraform apply`    | Apply changes to GCP (manual approval required)  |

> **Note**: The Terraform pipeline authenticates using the Terraform service account (SEC-012). The `Apply` stage requires manual approval (e.g., environment protection rules in GitHub Actions) to prevent unintended infrastructure changes. Details to be finalized during implementation.

> **Observability**: For observability of Terraform operations (GitHub Actions logs, Cloud Audit Logs, Git history), see OBS-009 in [07-observability-specifications.md](07-observability-specifications.md).

**Branch strategy**:
- `main` → Production
- `dev` → Development environment (also used for pre-production validation)
- Feature branches → PR preview (optional)

---

#### INFRA-008: Sitemap Generation (Cloud Function + Cloud Scheduler)

**Purpose**: Periodically regenerate the sitemap and store it in Firestore for serving via the `GET /sitemap.xml` API endpoint.

##### INFRA-008a: Cloud Function — `generate-sitemap`

**Purpose**: Internal Cloud Function that generates the sitemap XML from article data in Firestore.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Function name        | `generate-sitemap`                                 |
| Runtime              | Node.js 22 LTS (Cloud Functions Gen 2) (CLR-135)  |
| Region               | `asia-southeast1`                                  |
| Memory               | 256 MB                                             |
| Timeout              | 60 seconds                                         |
| Trigger              | HTTP (invoked by Cloud Scheduler)                  |
| Ingress              | Internal only (no public access)                   |
| VPC egress           | Direct VPC Egress (see INFRA-009) — Production only |
| Authentication       | Requires authentication (OIDC token from Cloud Scheduler service account) |

**Sitemap Generation Logic**:

1. Query all published articles from `technical_articles` and `blog_articles` collections.
2. Include static pages: `/`, `/technical`, `/blog`, `/socials`, `/others`, `/privacy`, `/changelog`. (CLR-106)
3. Article URLs SHALL include the `.md` extension (e.g., `https://tjmonsi.com/technical/article-title-2025-01-15-1030.md`).
4. THE SYSTEM SHALL exclude articles in the `others` category from the generated sitemap. Only articles in `blog` and `technical` categories SHALL be included in the sitemap. (CLR-175)
5. Build sitemap XML per the [Sitemaps protocol](https://www.sitemaps.org/protocol.html).
6. Write the generated XML to the `sitemap` Firestore collection (DM-010).
7. The `GET /sitemap.xml` public endpoint reads from this collection (BE-API-011).

**Sitemap URL Configuration**:

Each `<url>` entry in the sitemap SHALL include:

| URL Type | URL Pattern | `<priority>` | `<changefreq>` | `<lastmod>` |
| -------- | ----------- | ------------ | --------------- | ----------- |
| Homepage | `https://tjmonsi.com/` | `1.0` | `weekly` | Omit |
| Article detail (technical) | `https://tjmonsi.com/technical/{slug}.md` | `0.8` | `weekly` | `date_updated` (ISO 8601) |
| Article detail (blog) | `https://tjmonsi.com/blog/{slug}.md` | `0.8` | `weekly` | `date_updated` (ISO 8601) |
| List pages (`/technical`, `/blog`) | `https://tjmonsi.com/technical`, `https://tjmonsi.com/blog` | `0.6` | `weekly` | Omit |
| Static pages (`/socials`, `/others`, `/privacy`, `/changelog`) | `https://tjmonsi.com/socials`, etc. | `0.4` | `monthly` | Omit |

##### INFRA-008b: Cloud Scheduler — `trigger-sitemap-generation`

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Job name             | `trigger-sitemap-generation`                       |
| Schedule             | Every 6 hours (`0 */6 * * *`)                      |
| Target               | Cloud Function `generate-sitemap` (HTTP trigger)   |
| HTTP method          | POST                                               |
| Authentication       | OIDC token (service account with `roles/cloudfunctions.invoker` and `roles/run.invoker`) |
| Region               | `asia-southeast1`                                  |
| Retry config         | Max 3 retries with exponential backoff             |

**Notes**:
- The Cloud Function runs internally only and is NOT accessible from the public internet.
- The 6-hour schedule balances freshness with cost. Adjust based on content update frequency.

---

##### INFRA-008c: Cloud Function — `process-rate-limit-logs`

**Purpose**: Process Cloud Armor rate-limit (429) log entries via a log sink and write offense records to the `rate_limit_offenders` Firestore collection (DM-009). This bridges the gap between Cloud Armor's request-level rate limiting and the application's progressive banning logic — Cloud Armor blocks requests before they reach Cloud Run, so the Go application cannot directly observe rate-limited requests.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Function name        | `process-rate-limit-logs`                          |
| Runtime              | Node.js 22 LTS (Cloud Functions Gen 2) (CLR-135)  |
| Region               | `asia-southeast1`                                  |
| Memory               | 256 MB                                             |
| Timeout              | 60 seconds                                         |
| Trigger              | Cloud Logging log sink (via Pub/Sub)               |
| Ingress              | Internal only (no public access)                   |
| VPC egress           | Direct VPC Egress (see INFRA-009) — Production only |
| Authentication       | Service account with Firestore read/write access   |

**Log Sink Configuration**:

- A Cloud Logging log sink SHALL be configured to route Cloud Armor rate-limit events to a Pub/Sub topic.
- Log sink filter: `resource.type="http_load_balancer" AND httpRequest.status=429`
- The Pub/Sub topic triggers the `process-rate-limit-logs` Cloud Function.

**Pub/Sub Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Topic name           | `rate-limit-events`                                |
| Subscription         | Auto-created by Cloud Functions Gen 2 Eventarc trigger |
| Region               | `asia-southeast1`                                  |
| Message retention    | 7 days (default)                                   |

- The log sink publishes matching log entries to the `rate-limit-events` Pub/Sub topic.
- Cloud Functions Gen 2 uses an Eventarc trigger on this topic to invoke `process-rate-limit-logs`.
- The Pub/Sub topic and log sink are managed by Terraform (INFRA-016).

**Processing Logic**:

1. Receive Cloud Armor log entry from Pub/Sub.
2. Extract the client IP address from `httpRequest.remoteIp` and the request URL from `httpRequest.requestUrl` in the Cloud Logging log entry payload.
3. Look up or create the offender record in the `rate_limit_offenders` collection (DM-009) by client IP.
4. Use MongoDB `findOneAndUpdate` with `returnDocument: "after"` to atomically increment `offense_count` (via `$inc`) and append to `offense_history` (via `$push`), with `$setOnInsert` for new documents, and `upsert: true`. Returns the updated document. This ensures the ban evaluation in step 5 uses the post-increment document state, eliminating race conditions when multiple Cloud Function instances process concurrent Pub/Sub events for the same IP. (CLR-163, CLR-197)

   ```javascript
   db.rate_limit_offenders.findOneAndUpdate(
     { identifier: clientIP },
     {
       $inc: { offense_count: 1 },
       $push: {
         offense_history: {
           timestamp: new Date(),
           endpoint: extractedEndpoint
         }
       },
       $setOnInsert: {
         identifier: clientIP,
         ban_history: []
       }
     },
     { upsert: true, returnDocument: 'after' }
   )
   ```

5. Using the returned post-increment document, evaluate progressive banning thresholds using the rolling 7-day window algorithm (see SEC-002 in [06-security-specifications.md](06-security-specifications.md)):
   - 5 offenses within 7 days → set 30-day ban.
   - 2 offenses within 7 days after 30-day ban expires → set 90-day ban.
   - 2 offenses within 7 days after 90-day ban expires → set indefinite ban.
6. IF a ban threshold is met in step 5, update the offender record with the new `current_ban` and `ban_history` fields. IF no ban threshold is met, no additional write is needed (step 4 already persisted the offense increment). (CLR-197)

**Notes**:
- The Cloud Function runs internally only and is NOT accessible from the public internet.
- The Go application (Cloud Run) reads DM-009 on each incoming request to check ban status and enforce the appropriate response code (403 or 404).

---

##### INFRA-008d: Cloud Function — `cleanup-rate-limit-offenders`

**Purpose**: Periodically clean up expired rate limit offender records from the `rate_limit_offenders` Firestore collection (DM-009). Removes records where there is no active ban and no offenses in the last 90 days.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Function name        | `cleanup-rate-limit-offenders`                     |
| Runtime              | Node.js 22 LTS (Cloud Functions Gen 2) (CLR-135)  |
| Region               | `asia-southeast1`                                  |
| Memory               | 256 MB                                             |
| Timeout              | 60 seconds                                         |
| Trigger              | HTTP (invoked by Cloud Scheduler)                  |
| Ingress              | Internal only (no public access)                   |
| VPC egress           | Direct VPC Egress (see INFRA-009) — Production only |
| Authentication       | Requires authentication (OIDC token from Cloud Scheduler service account) |

**Cleanup Logic**:

1. Query all documents in the `rate_limit_offenders` collection (DM-009).
2. For each document, evaluate:
   - IF `current_ban` is null or expired (ban `end` date is in the past) AND the most recent entry in `offense_history` is older than 90 days → **delete** the document.
   - IF `current_ban.tier` is `"indefinite"` → **skip** (retain for periodic manual review).
3. Log the number of records evaluated, deleted, and retained.

**Notes**:
- The Cloud Function runs internally only and is NOT accessible from the public internet.
- Records with indefinite bans are retained and subject to periodic manual review by the website owner.
- This function is idempotent. Running it multiple times produces the same result.

##### INFRA-008e: Cloud Scheduler — `trigger-cleanup-rate-limit-offenders`

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Job name             | `trigger-cleanup-rate-limit-offenders`             |
| Schedule             | Daily at 03:00 UTC (`0 3 * * *`)                   |
| Target               | Cloud Function `cleanup-rate-limit-offenders` (HTTP trigger) |
| HTTP method          | POST                                               |
| Authentication       | OIDC token (service account with `roles/cloudfunctions.invoker` and `roles/run.invoker`) |
| Region               | `asia-southeast1`                                  |
| Retry config         | Max 3 retries with exponential backoff             |

**Notes**:
- Daily execution is sufficient given the 90-day retention window.
- Running at 03:00 UTC minimizes overlap with peak traffic (asia-southeast1 timezone).

---

#### INFRA-009: VPC Network (Production Only)

**Purpose**: Provide private networking for Cloud Run and Cloud Functions in the **Production** environment, restricting egress to Google Cloud APIs only. The Development environment does NOT use a VPC to reduce cost; services connect to Google Cloud APIs directly.

**Configuration**:

| Setting                  | Value                                              |
| ------------------------ | -------------------------------------------------- |
| VPC name                 | `personal-website-vpc`                             |
| Region                   | `asia-southeast1`                                  |
| Subnet (Direct VPC Egress) | `/27` subnet in `asia-southeast1` for Cloud Run and Cloud Functions Direct VPC Egress. Each Cloud Run instance or Cloud Function instance uses one IP address from this subnet. See: [IP address allocation](https://cloud.google.com/run/docs/configuring/shared-vpc-direct-vpc#direct-vpc-ip-allocation) (CLR-198) |
| Private Google Access    | Enabled (allows access to Google Cloud APIs without public IPs) |
| NAT                      | None (no Cloud NAT router)                         |
| Firewall rules           | Default deny egress to internet; allow egress to Google Cloud API ranges only |

**Direct VPC Egress**:

- Cloud Run and Cloud Functions Gen 2 SHALL use **Direct VPC Egress** instead of Serverless VPC Access Connectors. Direct VPC Egress provides VPC connectivity without provisioning a separate connector, at no additional cost. Reference: [Direct VPC Egress](https://cloud.google.com/run/docs/configuring/vpc-direct-vpc)
- **Cloud Run**: The Go backend API (INFRA-003) routes all egress traffic through the VPC via Direct VPC Egress. Enables private access to Firestore Enterprise and other Google Cloud services.
- **Cloud Functions**: The sitemap generation (INFRA-008a), log processing (INFRA-008c), offender cleanup (INFRA-008d), and embedding sync (INFRA-014) Cloud Functions route all egress traffic through the VPC via Direct VPC Egress.
- **IP Address Allocation**: Each Cloud Run revision or Cloud Function instance consumes one IP address from the configured subnet during execution. A `/27` subnet provides 32 IP addresses, providing sufficient headroom for the expected maximum concurrency (Cloud Run max 5 instances + up to 4 Cloud Function instances) with room for future scaling. GCP reserves some addresses per subnet, so usable IPs are fewer than the total. Monitor subnet utilization and expand if needed. (CLR-198)
- Reference: [Shared VPC Direct VPC IP Allocation](https://cloud.google.com/run/docs/configuring/shared-vpc-direct-vpc#direct-vpc-ip-allocation)

**Network Policy**:

- Cloud Run and Cloud Functions SHALL route all egress traffic through the VPC via **Direct VPC Egress** in **Production**.
- Egress SHALL be restricted to Google Cloud API endpoints only (via Private Google Access).
- No outbound internet access is required — all external dependencies are Google Cloud services. GeoIP resolution uses an embedded database file (MaxMind GeoLite2-Country) bundled in the Docker image — no external API calls required (CLR-133).
- No Cloud NAT router is provisioned to minimize cost and attack surface.
- In **Development**, no VPC is provisioned. Services connect to Google Cloud APIs directly to reduce cost.

---

#### INFRA-012: Firestore Native Mode Instance (Vector Search)

**Purpose**: Provide a Firestore Native Mode database for vector similarity search on article embeddings. This is separate from the Firestore Enterprise instance (MongoDB compat mode) used for application data.

**Configuration**:

| Setting                  | Value                                              |
| ------------------------ | -------------------------------------------------- |
| Database mode            | Firestore Native Mode                              |
| Database ID              | `vector-search` (named database, not `(default)`)  |
| Region                   | `asia-southeast1`                                  |
| Collections              | `technical_article_vectors`, `blog_article_vectors`, `others_vectors` |
| Vector indexes           | One per collection on `embedding` field (2048 dimensions, COSINE). 2048 is the maximum embedding dimension supported by Firestore Native. See: https://cloud.google.com/firestore/native/docs/vector-search |

**Vector Index Configuration** (per collection):

```
gcloud firestore indexes composite create \
  --database=vector-search \
  --collection-group=technical_article_vectors \
  --field-config=vector-config='{"dimension":2048,"flat":{}}',field-path=embedding
```

> Repeat for `blog_article_vectors` and `others_vectors`.

**Notes**:
- Firestore Native Mode is required for vector search (`findNearest()` API). Firestore Enterprise in MongoDB compat mode does not support native vector search.
- Both Firestore instances coexist in the same GCP project. The default database hosts Firestore Enterprise; the named database (`vector-search`) hosts Firestore Native.
- Reference: https://cloud.google.com/firestore/native/docs/vector-search

---

#### INFRA-013: Vertex AI — Gemini Embedding API

**Purpose**: Generate text embeddings using the Gemini `gemini-embedding-001` model via Vertex AI for semantic search.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| API                  | Vertex AI Embeddings API (`predict`)               |
| Model                | `gemini-embedding-001`                             |
| Region               | `asia-southeast1`                                  |
| Output dimensions    | 2048 (via `output_dimensionality` parameter; default is 3072; 2048 is Firestore Native max) |
| Task type (documents)| `RETRIEVAL_DOCUMENT` (used for document/article indexing by the embedding sync function) |
| Task type (queries)  | `RETRIEVAL_QUERY` (used for search query embedding at runtime by Cloud Run) |
| Normalization        | L2-normalize all 2048-dimensional vectors before storage (required for non-3072 dimensions) |
| Authentication       | IAM — service accounts with `roles/aiplatform.user` |

**API Endpoint**:
```
POST https://asia-southeast1-aiplatform.googleapis.com/v1/projects/{project}/locations/asia-southeast1/publishers/google/models/gemini-embedding-001:predict
```

**Usage**:

| Caller                                | Task Type            | Purpose                                    |
| ------------------------------------- | -------------------- | ------------------------------------------ |
| Cloud Run (Go API)                    | `RETRIEVAL_QUERY`    | Embed search queries on cache miss         |
| `sync-article-embeddings` (INFRA-014) | `RETRIEVAL_DOCUMENT` | Embed article content during sync          |

**Cost Considerations**:
- Pricing: per 1,000 characters of input text. See: https://cloud.google.com/vertex-ai/generative-ai/pricing
- The embedding cache (DM-011) eliminates redundant API calls for repeated search queries.
- Article embeddings are generated once per content change (not per request).

**Normalization Note**:
- The `gemini-embedding-001` model produces normalized embeddings at 3072 dimensions only. When using `output_dimensionality=2048`, the truncated embedding MUST be L2-normalized (divide each component by the L2 norm of the vector) before storage and comparison.

**Reference**: https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings

---

#### INFRA-014: Cloud Function — `sync-article-embeddings`

**Purpose**: Generate and synchronize article embedding vectors from Firestore Enterprise to Firestore Native Mode. Called by the content management CI/CD pipeline after articles are pushed to Firestore Enterprise.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Function name        | `sync-article-embeddings`                          |
| Runtime              | Node.js 22 LTS (Cloud Functions Gen 2) (CLR-135)   |
| Region               | `asia-southeast1`                                  |
| Memory               | 512 MB                                             |
| Timeout              | 300 seconds (5 minutes)                            |
| Trigger              | HTTP (invoked by content CI/CD pipeline or Cloud Scheduler) |
| Ingress              | Internal only (no public access)                   |
| VPC egress           | Direct VPC Egress (see INFRA-009) — Production only |
| Authentication       | Requires authentication (OIDC token — see callers below) |

**Callers and Authentication**:

| Caller                                   | Authentication Method                                      | IAM Roles Required                                                                |
| ---------------------------------------- | ---------------------------------------------------------- | --------------------------------------------------------------------------------- |
| Content CI/CD pipeline (GitHub Actions)  | Workload Identity Federation (OIDC token, no service account keys) | `roles/cloudfunctions.invoker`, `roles/run.invoker` (Gen 2 functions run on Cloud Run) |
| Cloud Scheduler (INFRA-014b)             | OIDC token from Cloud Scheduler service account            | `roles/cloudfunctions.invoker`, `roles/run.invoker`                               |

**Sync Logic**:

1. Read all articles from `technical_articles`, `blog_articles`, and `others` collections in Firestore Enterprise (via MongoDB driver or admin SDK).
2. For each article, construct the embedding source text: `title + "\n" + abstract + "\n" + category + "\n" + tags (comma-separated)`.
3. Compute SHA-256 hash of the source text.
4. Compare the hash with the `embedding_text_hash` field in the corresponding Firestore Native document. Also compare the document's `model_version` field against the currently configured embedding model version.
   - **If hash unchanged AND model_version matches**: Skip (no re-embedding needed).
   - **If hash changed, model_version mismatched, or new document**: Call Vertex AI Gemini `gemini-embedding-001` API with `task_type=RETRIEVAL_DOCUMENT` and `output_dimensionality=2048` to generate a 2048-dimensional embedding vector. L2-normalize the vector before writing to Firestore Native. (CLR-152)
5. Write/update the vector document in the appropriate Firestore Native collection (`technical_article_vectors`, `blog_article_vectors`, or `others_vectors`).
6. Delete vector documents from Firestore Native that no longer have corresponding articles in Firestore Enterprise (orphan cleanup).

**Notes**:
- This function is idempotent. Running it multiple times produces the same result.
- The hash-based change detection avoids unnecessary Gemini API calls, reducing cost.
- The content CI/CD pipeline SHALL call this function after successfully pushing content to Firestore Enterprise.
- Cloud Scheduler (INFRA-014b) triggers this function daily as a safety net to catch any missed syncs.
- IF a partial failure occurs during sync (e.g., embedding generation succeeds but Firestore Native write fails), THE SYSTEM SHALL log the failure with document ID and step name, skip the failed document, and continue processing remaining documents. Failed documents SHALL be retried on the next scheduled sync run. The sync log SHALL include a summary of succeeded, failed, and skipped document counts. (CLR-172)

**Integration Contract (Content CI/CD Pipeline)**:

The content management CI/CD pipeline is a **separate project** (GitHub repository) owned by the website owner. The pipeline's implementation is out of scope for this project. This section defines the integration points that the content pipeline MUST adhere to when interacting with this system.

1. **Authentication**: The content CI/CD pipeline (GitHub Actions) SHALL authenticate to GCP using [Workload Identity Federation](https://cloud.google.com/iam/docs/workload-identity-federation) (WIF). No long-lived service account keys are permitted (CLR-056, AD-022).
   - A Workload Identity Pool and Provider SHALL be configured in the GCP project to trust the content repository's GitHub Actions OIDC tokens.
   - The WIF-mapped service account SHALL have `roles/cloudfunctions.invoker` and `roles/run.invoker` on the `sync-article-embeddings` function.
   - Reference: [google-github-actions/auth](https://github.com/google-github-actions/auth)

2. **Invocation**: After pushing content to Firestore Enterprise, the content pipeline SHALL invoke this function via one of:
   - `gcloud functions call sync-article-embeddings --region=asia-southeast1` (using authenticated `gcloud` CLI), OR
   - An authenticated HTTP POST to the function's URL with an OIDC identity token in the `Authorization: Bearer <token>` header.

3. **Expected Firestore Enterprise Schema**: The content pipeline SHALL write articles to the following collections in Firestore Enterprise (MongoDB compat mode), conforming to the schemas defined in [04-data-model-specifications.md](04-data-model-specifications.md):
   - `technical_articles` (DM-002)
   - `blog_articles` (DM-003)
   - `others` (DM-005)
   - `categories` (DM-006)

4. **Sequence of Operations**: The content pipeline SHOULD follow this order on merge to main:
   1. Parse and validate markdown content.
   2. Push structured content to Firestore Enterprise.
   3. Update the `categories` collection with any new categories.
   4. Call `sync-article-embeddings` to synchronize embedding vectors.

5. **Error Handling**: If the call to `sync-article-embeddings` fails, the content pipeline SHOULD log the failure but NOT roll back the content push. The daily Cloud Scheduler safety net (INFRA-014b) ensures embeddings will be synchronized within 24 hours.

---

##### INFRA-014b: Cloud Scheduler — `trigger-sync-article-embeddings`

**Purpose**: Periodic safety net that triggers the `sync-article-embeddings` Cloud Function daily to catch any missed syncs from the content CI/CD pipeline.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Job name             | `trigger-sync-article-embeddings`                  |
| Schedule             | Daily at 04:00 UTC (`0 4 * * *`)                   |
| Target               | Cloud Function `sync-article-embeddings` (HTTP trigger) |
| HTTP method          | POST                                               |
| Authentication       | OIDC token (service account with `roles/cloudfunctions.invoker` and `roles/run.invoker`) |
| Region               | `asia-southeast1`                                  |
| Retry config         | Max 3 retries with exponential backoff             |

**Notes**:
- The function is idempotent — if all embeddings are already in sync (hash unchanged), the function exits quickly with no Gemini API calls.
- Running at 04:00 UTC minimizes overlap with peak traffic (asia-southeast1 timezone).
- This is the 3rd Cloud Scheduler job (alongside `trigger-sitemap-generation` and `trigger-cleanup-rate-limit-offenders`), within the free tier of 3 jobs.

---

#### INFRA-015: Cloud Storage — Terraform State Bucket

**Purpose**: Store Terraform remote state files for infrastructure-as-code management. This bucket is a **manually created bootstrap resource** — it is NOT managed by Terraform itself (chicken-and-egg: Terraform cannot manage the bucket that stores its own state).

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Bucket name          | `<project-id>-terraform-state`                     |
| Region               | `asia-southeast1`                                  |
| Storage class        | Standard                                           |
| Versioning           | Enabled (allows state rollback)                    |
| Public access        | Not public (uniform bucket-level access)           |
| Lifecycle rules      | None (state files are small and versioned)         |
| Provisioning         | **Manual** (created by the project owner via Console or `gcloud`) |

**Access Control**:

| Principal                              | Role                           | Purpose                                    |
| -------------------------------------- | ------------------------------ | ------------------------------------------ |
| Terraform service account (SEC-012)    | `roles/storage.objectAdmin`   | Read/write state files and lock files      |

**Notes**:
- The bucket stores only Terraform state (`.tfstate`) and lock files. Expected size: < 1 MB.
- Versioning is critical for state recovery in case of corruption or accidental overwrites. GCS versioning keeps all prior versions of state files.
- The bucket name uses the convention `<project-id>-terraform-state` for easy identification. Replace `<project-id>` with the actual project ID.
- No other service or user should have write access to this bucket to prevent state corruption.

---

#### INFRA-016: Terraform — Infrastructure as Code

**Purpose**: Manage GCP infrastructure resources declaratively using Terraform. Configuration files are stored in this repository; state is stored remotely in GCS (INFRA-015).

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Tool                 | Terraform (HashiCorp)                              |
| Config location      | This repository: `/terraform/` directory           |
| Remote backend       | GCS bucket `<project-id>-terraform-state` (INFRA-015)      |
| State locking        | GCS-based (built-in with GCS backend)              |
| Service account      | `terraform-builder@<project-id>.iam.gserviceaccount.com` (SEC-012) |
| Provisioning (SA)    | **Manual** (service account created by the project owner) |

**Backend Configuration** (expected in `/terraform/backend.tf`):

```hcl
terraform {
  backend "gcs" {
    bucket = "<project-id>-terraform-state"
    prefix = "terraform/state"
  }
}
```

**Scope of Terraform Management**:

Terraform manages GCP resources defined in the spec, including but not limited to:
- GCP API enablement (via `google_project_service` resources — e.g., `run.googleapis.com`, `cloudfunctions.googleapis.com`, `firestore.googleapis.com`, `compute.googleapis.com`, `aiplatform.googleapis.com`, `dns.googleapis.com`, `artifactregistry.googleapis.com`, `pubsub.googleapis.com`, `firebase.googleapis.com`, `sts.googleapis.com`, `iamcredentials.googleapis.com`, `eventarc.googleapis.com`, `cloudscheduler.googleapis.com`, `bigquery.googleapis.com`, `cloudbuild.googleapis.com`, etc.)
- Cloud Run services (INFRA-003) — service definition only; image deployment via CI/CD (see Deployment Boundary below)
- Cloud Functions (INFRA-008a, 008c, 008d, INFRA-014) — function configuration only; code deployment via CI/CD (see Deployment Boundary below)
- VPC and networking (INFRA-009)
- Cloud Armor security policies (INFRA-005)
- Cloud Load Balancer (INFRA-004)
- Cloud Scheduler jobs (INFRA-008b, INFRA-008e, INFRA-014b)
- Pub/Sub topics and subscriptions (INFRA-008c log sink trigger — `rate-limit-events` topic)
- Cloud Logging log sinks — BigQuery sinks (INFRA-010a–010e) + Pub/Sub sink for rate-limit events (INFRA-008c)
- BigQuery dataset (`website_logs`, INFRA-010) (CLR-140)
- Cloud Logging default bucket retention configuration (INFRA-007)
- Firestore Native database (INFRA-012)
- Artifact Registry (INFRA-018)
- Cloud DNS (INFRA-017)
- IAM bindings and service accounts (except bootstrap resources)
- Workload Identity Federation pools and providers (SEC-010 content CI/CD pool only; Terraform CI/CD pool is a bootstrap resource — see below)
- Vertex AI API enablement and IAM roles (no dedicated Vertex AI resources — only API calls from Cloud Run and Cloud Functions via `roles/aiplatform.user`)

**Resources NOT managed by Terraform** (Firebase CLI handles):

- Firebase Hosting site configuration, custom domain, rewrite rules, headers, and asset deployment (INFRA-001)
- Firebase Functions deployment (INFRA-002)

> **Note**: Terraform enables the Firebase API (`firebase.googleapis.com`) and creates the Firebase Hosting site resource (`google_firebase_hosting_site`). Custom domain configuration, rewrite rules (`firebase.json`), security headers (SEC-005), and deployment are all handled by `firebase deploy` via the CI/CD pipeline. See INFRA-001 and INFRA-002 for details.

**Firestore Enterprise (INFRA-006) — Terraform Support**:

Firestore Enterprise in MongoDB compatibility mode is a newer feature. The Terraform `google_firestore_database` resource support for this specific mode SHALL be verified during implementation.

- **If supported**: Terraform manages the database creation, mode selection (MongoDB compat), and region (`asia-southeast1`). Add to the Terraform scope.
- **If not supported**: Firestore Enterprise SHALL be provisioned manually (via Console or `gcloud`) and documented as a bootstrap prerequisite in the bootstrap resources table below. (CLR-150)

> **Note**: INFRA-016 Terraform scope excludes Firestore Enterprise provisioning if the Google Terraform provider does not support MongoDB compat mode. In that case, Firestore Enterprise SHALL be provisioned manually and documented as a bootstrap prerequisite.

**Deployment Boundary — Terraform Provisions, CI/CD Deploys**:

Terraform and the Application CI/CD pipeline have complementary but distinct responsibilities:

| Aspect | Terraform | CI/CD Pipeline |
| ------ | --------- | -------------- |
| Cloud Run | Creates service, configures scaling, memory, VPC, IAM, env vars | Deploys new container image revisions via `gcloud run deploy` |
| Cloud Functions | Creates functions, configures runtime, memory, triggers, IAM | Deploys new function code via `gcloud functions deploy` |
| Image/Code version | Ignored (`lifecycle { ignore_changes }` on image/code fields) | Managed — pushes new versions on merge |

- Terraform manages the _infrastructure definition_ (service configuration, scaling, networking, IAM).
- CI/CD manages the _application deployment_ (container images, function code).
- Terraform uses `lifecycle { ignore_changes }` on the container image field for Cloud Run and the source field for Cloud Functions. This prevents `terraform apply` from reverting CI/CD-deployed revisions to a stale image or code version.

**Bootstrap Resources** (manually created, NOT managed by Terraform):

| Resource                       | Reason                                                   |
| ------------------------------ | -------------------------------------------------------- |
| GCP Project                    | Must exist before Terraform can run                      |
| Terraform state bucket (INFRA-015) | Cannot manage its own state storage                  |
| Terraform service account (SEC-012) | Must exist to authenticate Terraform operations     |
| Terraform CI/CD WIF pool and provider (SEC-012) | Must exist before Terraform CI/CD pipeline can authenticate via Workload Identity Federation (chicken-and-egg) |
| Billing account link           | Pre-existing organizational resource                     |

**Notes**:
- Terraform configuration files will be added to this repository in a subsequent implementation phase. The current phase is documentation only.
- The `/terraform/` directory structure, module organization, and resource definitions are to be determined during implementation.
- State locking via GCS prevents concurrent Terraform runs from corrupting state.

---

#### INFRA-017: Cloud DNS

**Purpose**: Manage DNS zone and records for `tjmonsi.com` and `api.tjmonsi.com`, routing traffic to the Cloud Load Balancer (INFRA-004).

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Zone name            | `tjmonsi-com`                                      |
| DNS name             | `tjmonsi.com.`                                     |
| Visibility           | Public                                             |
| DNSSEC               | Enabled (recommended)                              |

**DNS Records**:

| Record Type | Name                  | Value                                      | TTL     |
| ----------- | --------------------- | ------------------------------------------ | ------- |
| A           | `tjmonsi.com`         | Cloud Load Balancer IP (INFRA-004)         | 300     |
| AAAA        | `tjmonsi.com`         | Cloud Load Balancer IPv6 (INFRA-004)       | 300     |
| A           | `api.tjmonsi.com`     | Cloud Load Balancer IP (INFRA-004)         | 300     |
| AAAA        | `api.tjmonsi.com`     | Cloud Load Balancer IPv6 (INFRA-004)       | 300     |
| CAA         | `tjmonsi.com`         | `0 issue "pki.goog"`                       | 3600    |

> **Note**: Both `tjmonsi.com` and `api.tjmonsi.com` point to the same Cloud Load Balancer. URL Map routing (INFRA-004) directs traffic to the appropriate backend (Firebase Hosting or Cloud Run) based on the hostname.

**Notes**:
- Cloud DNS is managed by Terraform (INFRA-016).
- NS records for the zone are auto-generated by Cloud DNS and must be configured at the domain registrar.
- TTL of 300 seconds (5 minutes) allows reasonably fast propagation during changes while reducing DNS query volume.
- CAA record restricts SSL certificate issuance to Google's certificate authority (`pki.goog`), which issues the Google-managed certificates used by the Load Balancer.

---

#### INFRA-018: Artifact Registry

**Purpose**: Store Docker container images for the Go backend API (INFRA-003). Cloud Run requires container images to be stored in Artifact Registry.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Repository name      | `website-images`                                   |
| Format               | Docker                                             |
| Region               | `asia-southeast1`                                  |
| Immutable tags       | Disabled (allow tag updates for `latest`)          |
| Cleanup policies     | Retain last 10 tagged versions; delete untagged images older than 7 days |

**Usage**:

- The Application CI/CD pipeline builds the Go backend Docker image and pushes it to: `asia-southeast1-docker.pkg.dev/<project-id>/website-images/<image-name>:<tag>`
- Cloud Run (INFRA-003) pulls the image from this repository.
- Terraform manages the Artifact Registry repository resource (INFRA-016). The CI/CD pipeline pushes images.

**Notes**:
- Artifact Registry is the recommended container registry for GCP. Container Registry (`gcr.io`) is deprecated.
- Expected storage: < 500 MB (small Go binary in distroless image). Within Artifact Registry's 500 MB free tier.
- The cleanup policy prevents unbounded storage growth from old image versions.

---

#### INFRA-019: Cloud Storage Media Bucket

**Purpose**: Store media assets (images) referenced by article markdown content. The Go backend proxies images from this bucket via `GET /images/{path}` (BE-API-013), enabling article markdown to reference images as `https://api.tjmonsi.com/images/...` while keeping the frontend CSP `img-src` restrictive (CLR-104).

**Configuration**:

| Setting              | Value                              |
| -------------------- | ---------------------------------- |
| Bucket name          | `<project-id>-media-bucket`        |
| Location             | `asia-southeast1`                  |
| Storage class        | Standard                           |
| Access control       | Uniform (no per-object ACLs)       |
| Public access        | Not public (accessed only via Go backend) |
| Versioning           | Enabled (CLR-110)                  |

**Access Control**:

- The Cloud Run API service account (`cloud-run-api@<project-id>.iam.gserviceaccount.com`) SHALL have `roles/storage.objectViewer` on this bucket (SEC-013).
- No public access is granted. All image access is proxied through the Go backend's `GET /images/{path}` endpoint.
- Image uploads are managed by the website owner directly (via `gsutil`, Cloud Console, or a future content pipeline). No upload endpoint is exposed in the API.

**Notes**:

- Expected storage: < 100 MB (a small personal website with limited images). Well within Cloud Storage's 5 GB free tier.
- The Go backend proxies images directly from Cloud Storage on each request. Cloud Storage serves as the authoritative source with no application-level caching. The frontend relies on HTTP `Cache-Control` headers for browser-level caching (see BE-API-013). (CLR-132)
- Terraform manages the bucket resource (INFRA-016).

---

#### INFRA-010: BigQuery Analytics Dataset & Log Sinks

**Purpose**: Route Cloud Logging logs to BigQuery for long-term storage, SQL-based analytics, and integration with Looker Studio dashboards.

**Dataset Configuration**:

| Setting              | Value                              |
| -------------------- | ---------------------------------- |
| Dataset name         | `website_logs`                     |
| Region               | `asia-southeast1`                  |
| Default table expiry | 730 days (2 years)                 |

**Log Sinks**:

Five Cloud Logging log sinks route logs to dedicated BigQuery tables within the `website_logs` dataset:

##### INFRA-010a: All Logs

| Setting          | Value                                              |
| ---------------- | -------------------------------------------------- |
| Sink name        | `sink-all-logs`                                    |
| Destination      | BigQuery table `website_logs.all_logs`              |
| Filter           | *(no filter — captures all project logs)*          |
| Purpose          | Complete log archive for ad-hoc SQL analysis       |

##### INFRA-010b: Cloud Armor & Load Balancer Logs

| Setting          | Value                                              |
| ---------------- | -------------------------------------------------- |
| Sink name        | `sink-cloud-armor-lb`                              |
| Destination      | BigQuery table `website_logs.cloud_armor_lb_logs`  |
| Filter           | `resource.type="http_load_balancer"`               |
| Table expiry     | **90 days** (overrides dataset default of 730 days) |
| Purpose          | WAF events, rate limiting analysis, DDoS investigation, security incident response |

> **Privacy Note**: Cloud Armor load balancer logs contain **full IP addresses** in the `httpRequest.remoteIp` field. These are generated by Google Cloud infrastructure at the load balancer level before requests reach the Go backend and cannot be truncated at the source. This table uses a 90-day retention period (shorter than the 2-year default) to limit the duration that full IPs are stored. Only the website owner has access to this table. Looker Studio dashboards SHALL NOT query this table for analytics reports — use `frontend_tracking_logs` (which contains truncated IPs) instead. This table is used solely for security investigations and DDoS analysis.

##### INFRA-010c: Frontend Error Logs

| Setting          | Value                                              |
| ---------------- | -------------------------------------------------- |
| Sink name        | `sink-frontend-errors`                             |
| Destination      | BigQuery table `website_logs.frontend_error_logs`  |
| Filter           | `resource.type="cloud_run_revision" AND jsonPayload.log_type="frontend_error"` |
| Purpose          | Client-side error trend analysis, browser/connection correlation |

**Note**: Requires the Go backend to emit a `log_type: "frontend_error"` field in structured log entries when processing `POST /t` requests with `action: "error_report"` (see OBS-001 in [07-observability-specifications.md](07-observability-specifications.md)).

##### INFRA-010d: Backend Error Logs

| Setting          | Value                                              |
| ---------------- | -------------------------------------------------- |
| Sink name        | `sink-backend-errors`                              |
| Destination      | BigQuery table `website_logs.backend_error_logs`   |
| Filter           | `resource.type="cloud_run_revision" AND resource.labels.service_name="website-api" AND severity>=ERROR AND NOT jsonPayload.log_type="frontend_error"` |
| Purpose          | Backend error trend analysis, masked 500 tracking  |

> **Note**: The `resource.labels.service_name` filter scopes this sink to the Go backend Cloud Run service only. Without it, ERROR logs from Cloud Functions Gen 2 (which also run on Cloud Run infrastructure under `resource.type="cloud_run_revision"`) would land in this table. The service name `website-api` is illustrative (see INFRA-003) and may be adjusted during implementation. (CLR-147)

##### INFRA-010e: Frontend Tracking Logs

| Setting          | Value                                              |
| ---------------- | -------------------------------------------------- |
| Sink name        | `sink-frontend-tracking`                           |
| Destination      | BigQuery table `website_logs.frontend_tracking_logs` |
| Filter           | `resource.type="cloud_run_revision" AND jsonPayload.log_type="frontend_tracking"` |
| Purpose          | Visitor analytics — unique visitors, page views, referrer sources, browser distribution |

**Note**: Requires the Go backend to emit a `log_type: "frontend_tracking"` field in structured log entries when processing `POST /t` requests with `action: "page_view"` or other tracking actions (see OBS-001 in [07-observability-specifications.md](07-observability-specifications.md)).

**BigQuery Table Schema**:

- All tables use the [Cloud Logging BigQuery schema](https://cloud.google.com/logging/docs/export/bigquery) automatically generated by the log sink export.
- Key queryable fields in the auto-generated schema:
  - `timestamp` — log entry timestamp
  - `severity` — log severity level
  - `jsonPayload` — structured log data (RECORD type, fields vary by log entry)
  - `resource` — resource metadata (type, labels)
  - `httpRequest` — HTTP request details (for load balancer logs)

**Data Retention**:

- All tables in the `website_logs` dataset SHALL have a default table expiry of **730 days (2 years)**. Data older than 2 years is automatically deleted by BigQuery.
- This 2-year retention applies to 4 of the 5 tables. The `cloud_armor_lb_logs` table overrides this to 90 days (see INFRA-010b). No table retains data indefinitely.
- The retention period balances long-term trend analysis with privacy obligations and cost management.

**Data Anonymization in BigQuery**:

- IP addresses exported to BigQuery via Cloud Logging log sinks are the same values logged by the Go backend. The Go backend SHALL truncate IPv4 addresses (zero the last octet, e.g., `203.0.113.0`) and truncate IPv6 addresses (zero the last 80 bits) **before** writing log entries. This ensures that no full IP addresses are stored in BigQuery.
- User-Agent strings exported to BigQuery contain browser name and version only (as sent by the frontend in the `POST /t` request body). Raw `User-Agent` headers from `httpRequest` fields in load balancer logs (`cloud_armor_lb_logs`) are retained as-is since they do not contain personally identifiable information beyond general browser/OS info.
- No cookies, user accounts, session identifiers, or device fingerprints are present in any BigQuery table.
- The `frontend_tracking_logs` and `frontend_error_logs` tables contain only the structured fields emitted by the Go backend when processing `POST /t` requests (see OBS-001, OBS-002, OBS-003 in [07-observability-specifications.md](07-observability-specifications.md)).

**Summary of Data Stored in BigQuery**:

| Table                     | Personal Data Present                         | Anonymization Applied                  | Retention |
| ------------------------- | --------------------------------------------- | -------------------------------------- | --------- |
| `all_logs`                | Truncated IP addresses                        | IP last octet zeroed                   | 2 years   |
| `cloud_armor_lb_logs`     | **Full** IP, User-Agent (browser/OS info)     | No IP truncation (infrastructure-generated logs); 90-day retention | 90 days |
| `frontend_error_logs`     | Truncated IP, browser name/version, geo_country | IP last octet zeroed                   | 2 years   |
| `backend_error_logs`      | Truncated IP (in request context)             | IP last octet zeroed                   | 2 years   |
| `frontend_tracking_logs`  | Truncated IP, browser, referrer, page visited, geo_country | IP last octet zeroed                   | 2 years   |

**Notes**:
- Log sinks operate independently of the existing Cloud Logging log buckets and the rate-limit log sink (INFRA-008c). They do not interfere with each other.
- BigQuery tables are partitioned by ingestion time automatically when created by log sinks.
- The 2-year table expiry is set at the dataset level as the default. Individual tables inherit this expiry unless explicitly overridden. Only the `cloud_armor_lb_logs` table overrides this default to 90 days for privacy reasons (see INFRA-010b).

---

#### INFRA-011: Looker Studio Integration

**Purpose**: Provide owner-operated analytics dashboards using Looker Studio connected to the BigQuery `website_logs` dataset.

**Service Account Configuration**:

| Setting                    | Value                                              |
| -------------------------- | -------------------------------------------------- |
| Service account name       | `looker-studio-reader`                             |
| Service account email      | `looker-studio-reader@<project-id>.iam.gserviceaccount.com` |
| BigQuery role (dataset)    | `roles/bigquery.dataViewer` on `website_logs` dataset |
| BigQuery role (project)    | `roles/bigquery.jobUser` on project (required to run queries) |
| Key type                   | Service account key (JSON) for Looker Studio data connector |

**Looker Studio Configuration**:

| Setting                    | Value                                              |
| -------------------------- | -------------------------------------------------- |
| Data source type           | BigQuery connector                                 |
| Authentication             | Service account (JSON key)                         |
| Tables connected           | All 5 tables in `website_logs` dataset             |
| Refresh schedule           | Automatic (Looker Studio default)                  |

**Analytics Capabilities**:

The following analytics are enabled by the BigQuery data via Looker Studio:

| Metric / Report              | Source Table                    | Description                                    |
| ---------------------------- | ------------------------------- | ---------------------------------------------- |
| Unique visitors              | `frontend_tracking_logs`        | Distinct `visitor_id` values per time period   |
| Page views over time         | `frontend_tracking_logs`        | Total and per-page view counts                 |
| Top pages by visits          | `frontend_tracking_logs`        | Most visited pages ranked                      |
| Referrer sources             | `frontend_tracking_logs`        | Traffic sources breakdown                      |
| Browser distribution         | `frontend_tracking_logs`        | Browser name/version breakdown                 |
| Geographic distribution      | `frontend_tracking_logs`        | Visitor locations derived from IP              |
| Connection speed analysis    | `frontend_tracking_logs`        | Visitor connection quality breakdown           |
| Frontend error trends        | `frontend_error_logs`           | Error frequency, types, and affected pages     |
| Error-browser correlation    | `frontend_error_logs`           | Errors grouped by browser/connection speed     |
| Backend error trends         | `backend_error_logs`            | Backend error frequency and types              |
| Masked 500 tracking          | `backend_error_logs`            | Internal errors masked as 404                  |
| Cloud Armor activity         | `cloud_armor_lb_logs`           | Rate limit blocks, WAF events over time        |
| Traffic patterns             | `cloud_armor_lb_logs`           | Request volume, geographic distribution        |
| Request latency analysis     | `all_logs`                      | API latency percentiles from structured logs   |

**Notes**:
- Looker Studio is owned and operated by the website owner. No public access.
- The service account has read-only access — it cannot modify or delete data.
- Looker Studio queries against BigQuery may incur costs based on the amount of data scanned. Use partitioned tables and targeted queries to minimize costs.

---

### Network Diagram

```
                    Internet
                       │
                       ▼
              ┌─────────────────┐
              │   Cloud DNS     │
              │   (INFRA-017)   │
              │  tjmonsi.com    │
              │ api.tjmonsi.com │
              └────────┬────────┘
                       │
                       ▼
              ┌─────────────────┐
              │  Cloud Armor    │
              │  (WAF / DDoS)   │
              └────────┬────────┘
                       │
                       ▼
              ┌─────────────────┐
              │  Cloud Load     │
              │  Balancer (L7)  │
              └───┬─────────┬───┘
                  │         │
        ┌─────────┘         └─────────┐
        ▼                             ▼
┌───────────────┐       ┌──── VPC (Production only) ────┐
│   Firebase    │       │                                │
│   Hosting +   │       │  ┌───────────────┐             │
│   Functions   │       │  │   Cloud Run   │             │
│   (SPA)       │       │  │   (Go API)    │             │
│               │       │  │   0-N inst.   │             │
│  Rewrites:    │       │  └───────┬───────┘             │
│  /sitemap.xml─│───────│──────────┘                     │
│               │       │          │                      │
│  Pages:       │       │          ▼                      │
│  / /technical │       │  ┌───────────────┐             │
│  /blog /others│       │  │   Firestore   │             │
│  /socials     │       │  │   Enterprise  │             │
│  /privacy     │       │  │   asia-se1    │             │
│  /changelog   │       │  └───────┬───────┘             │
└───────────────┘       │          ▲                      │
                        │          │                      │
                        │  ┌───────────────┐             │
                        │  │ Cloud Storage │             │
                        │  │ media-bucket  │             │
                        │  │ (images)      │             │
                        │  └───────────────┘             │
                        │          ▲                      │
                        │  Cloud Run reads               │
                        │  GET /images/{path}             │
                        │          ▲                      │
                        │  ┌───────┴───────┐             │
Cloud Scheduler ───────▶│  │Cloud Function │             │
                        │  │(Sitemap Gen)  │             │
                        │  └───────────────┘             │
                        │                                │
                        │  ┌───────────────┐             │
Pub/Sub ───────────────▶│  │Cloud Function │             │
(rate-limit-events) ───▶│  │(Log Proc.)    │             │
                        │  └───────────────┘             │
                        │          ▲                      │
                        │  Cloud Armor Log Sink           │
                        │                                │
                        │  ┌───────────────┐             │
Cloud Scheduler ───────▶│  │Cloud Function │             │
                        │  │(Cleanup)      │             │
                        │  └───────────────┘             │
                        │                                │
                        │  ┌───────────────┐             │
Content CI/CD (WIF) ───▶│  │Cloud Function │             │
Cloud Scheduler ───────▶│  │(Embed Sync)   │             │
                        │  │(daily safety) │             │
                        │  └───────┬───────┘             │
                        └──────────│─────────────────────┘
                                   │
                        ┌──────────▼─────────────────────┐
                        │   Firestore Native Mode        │
                        │   (Vector Search)              │
                        │   asia-southeast1              │
                        └────────────────────────────────┘
                                   ▲
                        Cloud Run + Embed Sync
                        query/write vectors
                        ┌────────────────────────────────┐
                        │   Vertex AI (Gemini)           │
                        │   gemini-embedding-001          │
                        └────────────────────────────────┘
                                   ▲
                        Cloud Run + Embed Sync
                        call for embeddings

              Cloud Logging (receives all service logs)
                           │
                ┌──────────┼──────────┐
                ▼          ▼          ▼
        ┌────────────┐  (5 Log Sinks)
        │  _Default  │
        │   bucket   │
        │  (90-day)  │
        └────────────┘
              ┌──────────────────────────────────┐
              │           BigQuery               │
              │    Dataset: website_logs          │
              │                                  │
              │  • all_logs                      │
              │  • cloud_armor_lb_logs           │
              │  • frontend_error_logs           │
              │  • backend_error_logs            │
              │  • frontend_tracking_logs        │
              └────────────┬─────────────────────┘
                           │ (Service Account)
                           ▼
              ┌──────────────────────────────────┐
              │        Looker Studio             │
              │   (Owner-operated analytics)     │
              └──────────────────────────────────┘

              ┌──────────────────────────────────┐
              │   Artifact Registry              │
              │   (INFRA-018)                    │
              │   website-images (Docker)        │
              │   asia-southeast1                │
              └──────────────────────────────────┘
                           ▲
              CI/CD pushes Docker images
              Cloud Run pulls images

              ┌──────────────────────────────────┐
              │   Terraform (IaC)                │
              │   Configs in /terraform/         │
              │   SA: terraform-builder@         │
              │      <project-id>                │
              │   Auth: WIF (GitHub Actions)     │
              └────────────┬─────────────────────┘
                           │ (remote state)
                           ▼
              ┌──────────────────────────────────┐
              │   Cloud Storage                  │
              │   <project-id>-terraform-state  │
              │   (manually created)             │
              └──────────────────────────────────┘
```

---

### Acceptance Criteria

- **AC-INFRA-001**: Given the Cloud Run service (INFRA-003), when deployed, then it runs with 1 vCPU, 1 GB RAM, min instances = 0, max instances = 5, and scale-to-zero is functional.
- **AC-INFRA-002**: Given the Load Balancer (INFRA-004), when configured, then `api.tjmonsi.com/*` routes to Cloud Run and `tjmonsi.com/*` routes to Firebase Hosting/Functions.
- **AC-INFRA-003**: Given Cloud Armor (INFRA-005), when a client exceeds 60 requests per minute, then the client receives HTTP `429` with a `Retry-After` header.
- **AC-INFRA-004**: Given the Firestore Enterprise database (INFRA-006), when accessed from the Go backend, then the MongoDB wire protocol connection succeeds via the MongoDB Go driver.
- **AC-INFRA-005**: Given the VPC (INFRA-009), when Cloud Run sends egress traffic, then Direct VPC Egress routes traffic through the VPC without a Serverless VPC Access Connector.
- **AC-INFRA-006**: Given the BigQuery dataset (INFRA-010), when log sinks are active, then logs are routed to the correct tables (`all_logs`, `cloud_armor_lb_logs`, `frontend_tracking_logs`, `frontend_error_logs`, `backend_error_logs`).
- **AC-INFRA-007**: Given the Terraform state bucket (INFRA-015), when Terraform runs, then state is stored in `<project-id>-terraform-state` with versioning enabled.
- **AC-INFRA-008**: Given DNS (INFRA-017), when `tjmonsi.com` and `api.tjmonsi.com` are resolved, then they point to the Load Balancer's IPv4 and IPv6 addresses.
- **AC-INFRA-009**: Given the Cloud Storage media bucket (INFRA-019), when the Go backend requests an image via `GET /images/{path}`, then the Cloud Run SA has `roles/storage.objectViewer` and can read the object.
- **AC-INFRA-010**: Given Firebase Hosting (INFRA-001), when static assets are deployed, then CSS/JS files are served with appropriate cache headers from the Firebase CDN.
- **AC-INFRA-011**: Given the Firestore Native Mode database (INFRA-012), when vector search is performed, then the `vector-search` named database exists with vector indexes on `technical_article_vectors`, `blog_article_vectors`, and `others_vectors` collections (2048 dimensions, COSINE distance) (CLR-131).
- **AC-INFRA-012**: Given the Vertex AI Embedding API (INFRA-013), when called with a text input and `output_dimensionality=2048`, then it returns a 2048-dimensional L2-normalized embedding vector (CLR-131).
- **AC-INFRA-013**: Given the `sync-article-embeddings` Cloud Function (INFRA-014), when triggered, then it reads articles from Firestore Enterprise, generates embeddings via Vertex AI for new/changed articles, and writes vectors to the corresponding Firestore Native collections (CLR-131).
- **AC-INFRA-014**: Given the Artifact Registry repository (INFRA-018), when the CI/CD pipeline pushes a Docker image, then the image is stored at `asia-southeast1-docker.pkg.dev/<project-id>/website-images/` and Cloud Run can pull from it (CLR-131).
- **AC-INFRA-015**: Given Cloud Logging (INFRA-007), when retention is configured, then the `_Default` log bucket retains logs for 90 days.
- **AC-INFRA-016**: Given the `generate-sitemap` Cloud Function (INFRA-008a), when triggered by Cloud Scheduler, then it reads article collections from Firestore Enterprise, generates a valid sitemap XML, and writes it to the `sitemap` collection (DM-010).
- **AC-INFRA-017**: Given the `process-rate-limit-logs` Cloud Function (INFRA-008c), when a Cloud Armor 429 log event is received via Pub/Sub (`rate-limit-events` topic), then it writes or updates an offense record in the `rate_limit_offenders` Firestore collection (DM-009).
- **AC-INFRA-018**: Given the `cleanup-rate-limit-offenders` Cloud Function (INFRA-008d), when triggered by Cloud Scheduler, then it deletes expired offender records (no active ban, no offenses in last 90 days) from the `rate_limit_offenders` collection.
- **AC-INFRA-019**: Given Cloud Scheduler jobs (INFRA-008b, 008e, 014b), when scheduled, then `trigger-sitemap-generation` runs every 6 hours, `trigger-cleanup-rate-limit-offenders` runs daily, and `trigger-sync-article-embeddings` runs daily at 04:00 UTC — all within the free tier of 3 jobs.
