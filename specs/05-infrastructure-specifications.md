---
title: Infrastructure Specifications
version: 2.6
date_created: 2026-02-17
last_updated: 2026-02-17
owner: TJ Monserrat
tags: [infrastructure, gcp, cloud-run, firebase, firestore, bigquery, looker-studio, vector-search, vertex-ai, terraform, iac]
---

## Infrastructure Specifications

### Google Cloud Project

- **Project ID**: `<project-id>` *(obfuscated — the GCP project already exists)*
- **Primary Region**: `asia-southeast1`
- **Billing**: Linked to billing account

> **Note**: The project ID is obfuscated in this documentation because it may be shared publicly for teaching purposes. Exposing the project ID could be an attack vector (e.g., targeted API abuse, resource enumeration). Replace `<project-id>` with the actual project ID in deployment configurations.

---

### Components

#### INFRA-001: Firebase Hosting

**Purpose**: Serve the Nuxt 4 SPA static assets (JS, CSS, images) globally via CDN.

**Configuration**:

- Hosting target: Static assets generated by Nuxt 4 build
- Custom domain: `tjmonsi.com`
- SSL/TLS: Managed by Firebase (automatic)
- Cache headers:
  - HTML files: `Cache-Control: no-cache` (always revalidate)
  - JS/CSS/assets with hash: `Cache-Control: public, max-age=31536000, immutable`
  - Images: `Cache-Control: public, max-age=86400`
- Firebase Functions handles SPA serving (all non-asset routes serve the SPA shell)
- **Rewrite rules** (`firebase.json`):
  - `/sitemap.xml` SHALL be rewritten to the Cloud Run backend service to proxy `tjmonsi.com/sitemap.xml` → `GET /sitemap.xml` on the backend API.

  ```json
  {
    "hosting": {
      "rewrites": [
        {
          "source": "/sitemap.xml",
          "run": {
            "serviceId": "<cloud-run-service-name>",
            "region": "asia-southeast1"
          }
        }
      ]
    }
  }
  ```

  - This ensures the sitemap URL declared in `robots.txt` (`https://tjmonsi.com/sitemap.xml`) is accessible on the frontend domain while being served by the backend.

---

#### INFRA-002: Firebase Functions

**Purpose**: Serve the Nuxt 4 SPA shell. When Nuxt 4 is deployed in SPA mode on Firebase Hosting, Firebase Functions is required to serve the SPA while Firebase Hosting serves the static JS/CSS assets.

**Reference**: https://nuxt.com/deploy/firebase

**Configuration**:

- Function runtime: Node.js (as required by Nuxt/Nitro)
- Region: `asia-southeast1` (same as Cloud Run for consistency)
- Purpose: Serve the SPA `index.html` shell for all client-side routes
- Memory: 256 MB (minimal, only serving static HTML)
- Max instances: Auto-scaled by Firebase

---

#### INFRA-003: Google Cloud Run

**Purpose**: Host the Go backend API.

**Configuration**:

| Setting              | Value                           |
| -------------------- | ------------------------------- |
| Container runtime    | Go binary in minimal Docker image |
| Region               | `asia-southeast1`               |
| Min instances        | 0 (scale to zero)               |
| Max instances        | 5                               |
| CPU                  | 1 vCPU                          |
| Memory               | 1 GB                            |
| Concurrency          | 160                             |
| Request timeout      | 30 seconds                      |
| Startup CPU boost    | Enabled                         |
| Ingress              | Internal + Cloud Load Balancing |
| VPC egress          | Connected to `personal-website-vpc` via **Direct VPC Egress** (see INFRA-009) — Production only. Development environment does NOT use a VPC. |

**Docker Image**:

```dockerfile
# Multi-stage build
FROM golang:1.23-alpine AS builder
WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -o server .

# Create non-root user 'jack' in builder (distroless has no shell/useradd)
RUN addgroup -S jack && adduser -S -G jack -u 10001 jack

FROM gcr.io/distroless/static-debian12

# Copy passwd/group so the runtime knows about 'jack'
COPY --from=builder /etc/passwd /etc/passwd
COPY --from=builder /etc/group /etc/group

COPY --from=builder /app/server /server

# Run as non-root user 'jack' — no root credentials or privileges
USER jack:jack

EXPOSE 8080
ENTRYPOINT ["/server"]
```

**Container Security**:

- The container SHALL run as the non-root user `jack` (UID 10001). Root credentials and privileges are not present at runtime.
- The `gcr.io/distroless/static-debian12` base image contains no shell, package manager, or unnecessary binaries — reducing the attack surface.
- The `USER jack:jack` directive ensures the process cannot escalate to root.
- Cloud Run SHALL be configured with `--no-allow-unauthenticated` for internal endpoints and `run.googleapis.com/container-security-context: {"runAsNonRoot": true}` annotation where supported.

**Health Check**: `GET /health` (returns `200` with `{"status": "ok"}`)

---

#### INFRA-004: Google Cloud Load Balancer

**Purpose**: Route traffic, SSL termination, and integration with Cloud Armor.

**Configuration**:

- Type: External Application Load Balancer (Global)
- Backend services:
  - Firebase Hosting (frontend)
  - Cloud Run (backend API)
- SSL Certificate: Google-managed
- URL Map routing:
  - `api.tjmonsi.com/*` → Cloud Run backend
  - `tjmonsi.com/*` → Firebase Hosting + Functions
- Subdomain routing is used to separate frontend and backend traffic.

---

#### INFRA-005: Google Cloud Armor

**Purpose**: WAF and DDoS protection.

**Policies**:

| Rule Priority | Description                              | Action    |
| ------------- | ---------------------------------------- | --------- |
| 500           | Block public access to `/health`         | Deny (403)|
| 1000          | Block known malicious IP ranges          | Deny      |
| 2000          | Rate limiting (60 req/min per IP)        | Throttle  |
| 3000          | Block SQL injection patterns             | Deny      |
| 4000          | Block XSS patterns                       | Deny      |
| 5000          | Block path traversal attempts            | Deny      |
| 9999          | Default allow                            | Allow     |

**Rate Limiting at Cloud Armor level**:

- **Primary rate limiting enforcement**: Cloud Armor handles per-IP rate limiting at the load balancer level. This eliminates the need for application-level in-memory rate counters, which would not persist across Cloud Run instance scaling events.
- **Single rate limit tier**: 60 requests per minute per IP for all clients and all endpoints. No differentiation between user types, bot detection tiers, or endpoint-specific limits.
- Action: HTTP `429` response with `Retry-After` header when limits are exceeded.
- **Progressive banning**: Offender records and ban state are stored in Firestore (`rate_limit_offenders` collection, DM-009). The Go application checks Firestore for ban status on each request and enforces progressive banning logic (see SEC-002 in [06-security-specifications.md](06-security-specifications.md)).
- Note: Cloud Armor provides the rate limiting layer; the application reads offender state from Firestore to enforce progressive banning tiers (429 → 403 → 404).

**Adaptive Protection**:

- Cloud Armor Adaptive Protection SHALL be enabled to provide automatic, ML-based escalating DDoS mitigation.
- Adaptive Protection complements the manual rate-limiting rules by automatically detecting and mitigating L7 DDoS attacks without manual rule updates.
- Reference: [Cloud Armor Adaptive Protection](https://cloud.google.com/armor/docs/adaptive-protection-overview)

**Custom Error Response for 429**:

- Cloud Armor SHALL be configured with a [custom error response](https://cloud.google.com/armor/docs/custom-error-responses) for HTTP 429 status codes.
- The custom error response SHALL return `Content-Type: application/json` with the following body:

```json
{
  "error": "Too many requests. Please try again later.",
  "retry_after": 30
}
```

- Note: Even with this custom error response configured, the frontend (FE-COMP-003) matches 429 responses by status code only and does not depend on the response body format.

---

#### INFRA-006: Database

**Technology**: Firestore Enterprise in MongoDB compatibility mode

**References**:
- Firestore Enterprise: https://firebase.google.com/docs/firestore/enterprise/overview-enterprise-edition-modes
- MongoDB Compatibility Mode: https://firebase.google.com/docs/firestore/enterprise/mongodb-compatibility-overview

| Setting          | Value                              |
| ---------------- | ---------------------------------- |
| Mode             | MongoDB compatibility              |
| Region           | `asia-southeast1`                  |
| Driver           | MongoDB Go driver (standard wire protocol) |
| Security         | Backend-only access (no direct client access) |
| Network access   | Private endpoint or IP allowlist from Cloud Run |
| Backup           | Enabled (managed by Firestore Enterprise) |

---

#### INFRA-007: Google Cloud Logging & Monitoring

**Purpose**: Centralized observability.

**Configuration**:

- **Structured logging** from Cloud Run (JSON format)
- **Log sinks**: Route error logs to a dedicated log bucket with 90-day retention
- **BigQuery log sinks**: Route logs to BigQuery dataset for long-term analytics and SQL querying (see INFRA-010)
- **Alerts**:
  - Error rate > 1% of requests over 5 minutes
  - Latency P95 > 2 seconds over 5 minutes
  - Cloud Run instance memory > 80%
  - Any masked 500 error logged
- **Dashboards**: Request rate, latency, error rate, Cloud Run instance count

---

### CI/CD Pipeline

**Tool**: GitHub Actions (assumed, given `.github/` directory exists)

**Pipeline stages (Application)**:

```
┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐
│   Lint   │───▶│   Test   │───▶│  Build   │───▶│  Deploy  │
└──────────┘    └──────────┘    └──────────┘    └──────────┘
```

| Stage   | Frontend                        | Backend                        |
| ------- | ------------------------------- | ------------------------------ |
| Lint    | ESLint, Stylelint               | golangci-lint                  |
| Test    | Vitest (unit), Playwright (E2E) | `go test`                      |
| Build   | `nuxt generate`                 | Docker build                   |
| Deploy  | Firebase deploy                 | Cloud Run deploy               |

**Pipeline stages (Infrastructure — Terraform)**:

```
┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐
│  Format  │───▶│ Validate │───▶│   Plan   │───▶│  Apply   │
└──────────┘    └──────────┘    └──────────┘    └──────────┘
```

| Stage    | Tool / Command       | Notes                                            |
| -------- | -------------------- | ------------------------------------------------ |
| Format   | `terraform fmt`      | Verify formatting consistency                    |
| Validate | `terraform validate` | Syntax and configuration validation              |
| Plan     | `terraform plan`     | Preview changes; output saved as artifact        |
| Apply    | `terraform apply`    | Apply changes to GCP (manual approval required)  |

> **Note**: The Terraform pipeline authenticates using the Terraform service account (SEC-012). The `Apply` stage requires manual approval (e.g., environment protection rules in GitHub Actions) to prevent unintended infrastructure changes. Details to be finalized during implementation.

**Branch strategy**:
- `main` → Production
- `dev` → Development environment (also used for pre-production validation)
- Feature branches → PR preview (optional)

---

#### INFRA-008: Sitemap Generation (Cloud Function + Cloud Scheduler)

**Purpose**: Periodically regenerate the sitemap and store it in Firestore for serving via the `GET /sitemap.xml` API endpoint.

##### INFRA-008a: Cloud Function — `generate-sitemap`

**Purpose**: Internal Cloud Function that generates the sitemap XML from article data in Firestore.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Function name        | `generate-sitemap`                                 |
| Runtime              | Node.js (Cloud Functions Gen 2)                    |
| Region               | `asia-southeast1`                                  |
| Memory               | 256 MB                                             |
| Timeout              | 60 seconds                                         |
| Trigger              | HTTP (invoked by Cloud Scheduler)                  |
| Ingress              | Internal only (no public access)                   |
| VPC egress           | Direct VPC Egress (see INFRA-009) — Production only |
| Authentication       | Requires authentication (OIDC token from Cloud Scheduler service account) |

**Sitemap Generation Logic**:

1. Query all published articles from `technical_articles` and `blog_articles` collections.
2. Include static pages: `/`, `/technical`, `/blog`, `/socials`, `/others`, `/privacy`.
3. Article URLs SHALL include the `.md` extension (e.g., `https://tjmonsi.com/technical/article-title-2025-01-15-1030.md`).
4. Build sitemap XML per the [Sitemaps protocol](https://www.sitemaps.org/protocol.html).
5. Write the generated XML to the `sitemap` Firestore collection (DM-010).
6. The `GET /sitemap.xml` public endpoint reads from this collection (BE-API-011).

##### INFRA-008b: Cloud Scheduler — `trigger-sitemap-generation`

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Job name             | `trigger-sitemap-generation`                       |
| Schedule             | Every 6 hours (`0 */6 * * *`)                      |
| Target               | Cloud Function `generate-sitemap` (HTTP trigger)   |
| HTTP method          | POST                                               |
| Authentication       | OIDC token (service account with Cloud Functions invoker role) |
| Region               | `asia-southeast1`                                  |
| Retry config         | Max 3 retries with exponential backoff             |

**Notes**:
- The Cloud Function runs internally only and is NOT accessible from the public internet.
- The 6-hour schedule balances freshness with cost. Adjust based on content update frequency.

---

##### INFRA-008c: Cloud Function — `process-rate-limit-logs`

**Purpose**: Process Cloud Armor rate-limit (429) log entries via a log sink and write offense records to the `rate_limit_offenders` Firestore collection (DM-009). This bridges the gap between Cloud Armor's request-level rate limiting and the application's progressive banning logic — Cloud Armor blocks requests before they reach Cloud Run, so the Go application cannot directly observe rate-limited requests.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Function name        | `process-rate-limit-logs`                          |
| Runtime              | Node.js (Cloud Functions Gen 2)                    |
| Region               | `asia-southeast1`                                  |
| Memory               | 256 MB                                             |
| Timeout              | 60 seconds                                         |
| Trigger              | Cloud Logging log sink (via Pub/Sub)               |
| Ingress              | Internal only (no public access)                   |
| VPC egress           | Direct VPC Egress (see INFRA-009) — Production only |
| Authentication       | Service account with Firestore read/write access   |

**Log Sink Configuration**:

- A Cloud Logging log sink SHALL be configured to route Cloud Armor rate-limit events to a Pub/Sub topic.
- Log sink filter: Cloud Armor logs where the response status is `429` (rate limit exceeded).
- The Pub/Sub topic triggers the `process-rate-limit-logs` Cloud Function.

**Processing Logic**:

1. Receive Cloud Armor log entry from Pub/Sub.
2. Extract the client IP address from the log entry.
3. Look up or create the offender record in the `rate_limit_offenders` collection (DM-009) by client IP.
4. Increment `offense_count` and append to `offense_history`.
5. Evaluate progressive banning thresholds (see SEC-002 in [06-security-specifications.md](06-security-specifications.md)):
   - 5 offenses within 7 days → set 30-day ban.
   - 2 offenses after 30-day ban expires → set 90-day ban.
   - 2 offenses after 90-day ban expires → set indefinite ban.
6. Write updated record to Firestore.

**Notes**:
- The Cloud Function runs internally only and is NOT accessible from the public internet.
- The Go application (Cloud Run) reads DM-009 on each incoming request to check ban status and enforce the appropriate response code (403 or 404).

---

##### INFRA-008d: Cloud Function — `cleanup-rate-limit-offenders`

**Purpose**: Periodically clean up expired rate limit offender records from the `rate_limit_offenders` Firestore collection (DM-009). Removes records where there is no active ban and no offenses in the last 90 days.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Function name        | `cleanup-rate-limit-offenders`                     |
| Runtime              | Node.js (Cloud Functions Gen 2)                    |
| Region               | `asia-southeast1`                                  |
| Memory               | 256 MB                                             |
| Timeout              | 60 seconds                                         |
| Trigger              | HTTP (invoked by Cloud Scheduler)                  |
| Ingress              | Internal only (no public access)                   |
| VPC egress           | Direct VPC Egress (see INFRA-009) — Production only |
| Authentication       | Requires authentication (OIDC token from Cloud Scheduler service account) |

**Cleanup Logic**:

1. Query all documents in the `rate_limit_offenders` collection (DM-009).
2. For each document, evaluate:
   - IF `current_ban` is null or expired (ban `end` date is in the past) AND the most recent entry in `offense_history` is older than 90 days → **delete** the document.
   - IF `current_ban.tier` is `"indefinite"` → **skip** (retain for periodic manual review).
3. Log the number of records evaluated, deleted, and retained.

**Notes**:
- The Cloud Function runs internally only and is NOT accessible from the public internet.
- Records with indefinite bans are retained and subject to periodic manual review by the website owner.
- This function is idempotent. Running it multiple times produces the same result.

##### INFRA-008e: Cloud Scheduler — `trigger-cleanup-rate-limit-offenders`

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Job name             | `trigger-cleanup-rate-limit-offenders`             |
| Schedule             | Daily at 03:00 UTC (`0 3 * * *`)                   |
| Target               | Cloud Function `cleanup-rate-limit-offenders` (HTTP trigger) |
| HTTP method          | POST                                               |
| Authentication       | OIDC token (service account with Cloud Functions invoker role) |
| Region               | `asia-southeast1`                                  |
| Retry config         | Max 3 retries with exponential backoff             |

**Notes**:
- Daily execution is sufficient given the 90-day retention window.
- Running at 03:00 UTC minimizes overlap with peak traffic (asia-southeast1 timezone).

---

#### INFRA-009: VPC Network (Production Only)

**Purpose**: Provide private networking for Cloud Run and Cloud Functions in the **Production** environment, restricting egress to Google Cloud APIs only. The Development environment does NOT use a VPC to reduce cost; services connect to Google Cloud APIs directly.

**Configuration**:

| Setting                  | Value                                              |
| ------------------------ | -------------------------------------------------- |
| VPC name                 | `personal-website-vpc`                             |
| Region                   | `asia-southeast1`                                  |
| Subnet (Direct VPC Egress) | `/28` subnet in `asia-southeast1` for Cloud Run and Cloud Functions Direct VPC Egress. Each Cloud Run instance or Cloud Function instance uses one IP address from this subnet. See: [IP address allocation](https://cloud.google.com/run/docs/configuring/shared-vpc-direct-vpc#direct-vpc-ip-allocation) |
| Private Google Access    | Enabled (allows access to Google Cloud APIs without public IPs) |
| NAT                      | None (no Cloud NAT router)                         |
| Firewall rules           | Default deny egress to internet; allow egress to Google Cloud API ranges only |

**Direct VPC Egress**:

- Cloud Run and Cloud Functions Gen 2 SHALL use **Direct VPC Egress** instead of Serverless VPC Access Connectors. Direct VPC Egress provides VPC connectivity without provisioning a separate connector, at no additional cost. Reference: [Direct VPC Egress](https://cloud.google.com/run/docs/configuring/vpc-direct-vpc)
- **Cloud Run**: The Go backend API (INFRA-003) routes all egress traffic through the VPC via Direct VPC Egress. Enables private access to Firestore Enterprise and other Google Cloud services.
- **Cloud Functions**: The sitemap generation (INFRA-008a), log processing (INFRA-008c), offender cleanup (INFRA-008d), and embedding sync (INFRA-014) Cloud Functions route all egress traffic through the VPC via Direct VPC Egress.
- **IP Address Allocation**: Each Cloud Run revision or Cloud Function instance consumes one IP address from the configured subnet during execution. A `/28` subnet provides 16 IP addresses, sufficient for the expected maximum concurrency (Cloud Run max 5 instances + up to 4 Cloud Function instances). Monitor subnet utilization and expand if needed.
- Reference: [Shared VPC Direct VPC IP Allocation](https://cloud.google.com/run/docs/configuring/shared-vpc-direct-vpc#direct-vpc-ip-allocation)

**Network Policy**:

- Cloud Run and Cloud Functions SHALL route all egress traffic through the VPC via **Direct VPC Egress** in **Production**.
- Egress SHALL be restricted to Google Cloud API endpoints only (via Private Google Access).
- No outbound internet access is required — all external dependencies are Google Cloud services.
- No Cloud NAT router is provisioned to minimize cost and attack surface.
- In **Development**, no VPC is provisioned. Services connect to Google Cloud APIs directly to reduce cost.

---

#### INFRA-012: Firestore Native Mode Instance (Vector Search)

**Purpose**: Provide a Firestore Native Mode database for vector similarity search on article embeddings. This is separate from the Firestore Enterprise instance (MongoDB compat mode) used for application data.

**Configuration**:

| Setting                  | Value                                              |
| ------------------------ | -------------------------------------------------- |
| Database mode            | Firestore Native Mode                              |
| Database ID              | `vector-search` (named database, not `(default)`)  |
| Region                   | `asia-southeast1`                                  |
| Collections              | `technical_article_vectors`, `blog_article_vectors`, `others_vectors` |
| Vector indexes           | One per collection on `embedding` field (2048 dimensions, COSINE). 2048 is the maximum embedding dimension supported by Firestore Native. See: https://cloud.google.com/firestore/native/docs/vector-search |

**Vector Index Configuration** (per collection):

```
gcloud firestore indexes composite create \
  --database=vector-search \
  --collection-group=technical_article_vectors \
  --field-config=vector-config='{"dimension":2048,"flat":{}}',field-path=embedding
```

> Repeat for `blog_article_vectors` and `others_vectors`.

**Notes**:
- Firestore Native Mode is required for vector search (`findNearest()` API). Firestore Enterprise in MongoDB compat mode does not support native vector search.
- Both Firestore instances coexist in the same GCP project. The default database hosts Firestore Enterprise; the named database (`vector-search`) hosts Firestore Native.
- Reference: https://cloud.google.com/firestore/native/docs/vector-search

---

#### INFRA-013: Vertex AI — Gemini Embedding API

**Purpose**: Generate text embeddings using the Gemini `gemini-embedding-001` model via Vertex AI for semantic search.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| API                  | Vertex AI Embeddings API (`predict`)               |
| Model                | `gemini-embedding-001`                             |
| Region               | `asia-southeast1`                                  |
| Output dimensions    | 2048 (via `output_dimensionality` parameter; default is 3072; 2048 is Firestore Native max) |
| Task type (documents)| `RETRIEVAL_DOCUMENT` (used for document/article indexing by the embedding sync function) |
| Task type (queries)  | `RETRIEVAL_QUERY` (used for search query embedding at runtime by Cloud Run) |
| Normalization        | L2-normalize all 2048-dimensional vectors before storage (required for non-3072 dimensions) |
| Authentication       | IAM — service accounts with `roles/aiplatform.user` |

**API Endpoint**:
```
POST https://asia-southeast1-aiplatform.googleapis.com/v1/projects/{project}/locations/asia-southeast1/publishers/google/models/gemini-embedding-001:predict
```

**Usage**:

| Caller                                | Task Type            | Purpose                                    |
| ------------------------------------- | -------------------- | ------------------------------------------ |
| Cloud Run (Go API)                    | `RETRIEVAL_QUERY`    | Embed search queries on cache miss         |
| `sync-article-embeddings` (INFRA-014) | `RETRIEVAL_DOCUMENT` | Embed article content during sync          |

**Cost Considerations**:
- Pricing: per 1,000 characters of input text. See: https://cloud.google.com/vertex-ai/generative-ai/pricing
- The embedding cache (DM-011) eliminates redundant API calls for repeated search queries.
- Article embeddings are generated once per content change (not per request).

**Normalization Note**:
- The `gemini-embedding-001` model produces normalized embeddings at 3072 dimensions only. When using `output_dimensionality=2048`, the truncated embedding MUST be L2-normalized (divide each component by the L2 norm of the vector) before storage and comparison.

**Reference**: https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings

---

#### INFRA-014: Cloud Function — `sync-article-embeddings`

**Purpose**: Generate and synchronize article embedding vectors from Firestore Enterprise to Firestore Native Mode. Called by the content management CI/CD pipeline after articles are pushed to Firestore Enterprise.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Function name        | `sync-article-embeddings`                          |
| Runtime              | Node.js (Cloud Functions Gen 2)                    |
| Region               | `asia-southeast1`                                  |
| Memory               | 512 MB                                             |
| Timeout              | 300 seconds (5 minutes)                            |
| Trigger              | HTTP (invoked by content CI/CD pipeline or Cloud Scheduler) |
| Ingress              | Internal only (no public access)                   |
| VPC egress           | Direct VPC Egress (see INFRA-009) — Production only |
| Authentication       | Requires authentication (OIDC token — see callers below) |

**Callers and Authentication**:

| Caller                                   | Authentication Method                                      | IAM Roles Required                                                                |
| ---------------------------------------- | ---------------------------------------------------------- | --------------------------------------------------------------------------------- |
| Content CI/CD pipeline (GitHub Actions)  | Workload Identity Federation (OIDC token, no service account keys) | `roles/cloudfunctions.invoker`, `roles/run.invoker` (Gen 2 functions run on Cloud Run) |
| Cloud Scheduler (INFRA-014b)             | OIDC token from Cloud Scheduler service account            | `roles/cloudfunctions.invoker`, `roles/run.invoker`                               |

**Sync Logic**:

1. Read all articles from `technical_articles`, `blog_articles`, and `others` collections in Firestore Enterprise (via MongoDB driver or admin SDK).
2. For each article, construct the embedding source text: `title + "\n" + abstract + "\n" + category + "\n" + tags (comma-separated)`.
3. Compute SHA-256 hash of the source text.
4. Compare the hash with the `embedding_text_hash` field in the corresponding Firestore Native document.
   - **If unchanged**: Skip (no re-embedding needed).
   - **If changed or new**: Call Vertex AI Gemini `gemini-embedding-001` API with `task_type=RETRIEVAL_DOCUMENT` and `output_dimensionality=2048` to generate a 2048-dimensional embedding vector. L2-normalize the vector before writing to Firestore Native.
5. Write/update the vector document in the appropriate Firestore Native collection (`technical_article_vectors`, `blog_article_vectors`, or `others_vectors`).
6. Delete vector documents from Firestore Native that no longer have corresponding articles in Firestore Enterprise (orphan cleanup).

**Notes**:
- This function is idempotent. Running it multiple times produces the same result.
- The hash-based change detection avoids unnecessary Gemini API calls, reducing cost.
- The content CI/CD pipeline SHALL call this function after successfully pushing content to Firestore Enterprise.
- Cloud Scheduler (INFRA-014b) triggers this function daily as a safety net to catch any missed syncs.

**Integration Contract (Content CI/CD Pipeline)**:

The content management CI/CD pipeline is a **separate project** (GitHub repository) owned by the website owner. The pipeline's implementation is out of scope for this project. This section defines the integration points that the content pipeline MUST adhere to when interacting with this system.

1. **Authentication**: The content CI/CD pipeline (GitHub Actions) SHALL authenticate to GCP using [Workload Identity Federation](https://cloud.google.com/iam/docs/workload-identity-federation) (WIF). No long-lived service account keys are permitted (CLR-056, AD-022).
   - A Workload Identity Pool and Provider SHALL be configured in the GCP project to trust the content repository's GitHub Actions OIDC tokens.
   - The WIF-mapped service account SHALL have `roles/cloudfunctions.invoker` and `roles/run.invoker` on the `sync-article-embeddings` function.
   - Reference: [google-github-actions/auth](https://github.com/google-github-actions/auth)

2. **Invocation**: After pushing content to Firestore Enterprise, the content pipeline SHALL invoke this function via one of:
   - `gcloud functions call sync-article-embeddings --region=asia-southeast1` (using authenticated `gcloud` CLI), OR
   - An authenticated HTTP POST to the function's URL with an OIDC identity token in the `Authorization: Bearer <token>` header.

3. **Expected Firestore Enterprise Schema**: The content pipeline SHALL write articles to the following collections in Firestore Enterprise (MongoDB compat mode), conforming to the schemas defined in [04-data-model-specifications.md](04-data-model-specifications.md):
   - `technical_articles` (DM-002)
   - `blog_articles` (DM-003)
   - `others` (DM-005)
   - `categories` (DM-006)

4. **Sequence of Operations**: The content pipeline SHOULD follow this order on merge to main:
   1. Parse and validate markdown content.
   2. Push structured content to Firestore Enterprise.
   3. Update the `categories` collection with any new categories.
   4. Call `sync-article-embeddings` to synchronize embedding vectors.

5. **Error Handling**: If the call to `sync-article-embeddings` fails, the content pipeline SHOULD log the failure but NOT roll back the content push. The daily Cloud Scheduler safety net (INFRA-014b) ensures embeddings will be synchronized within 24 hours.

---

##### INFRA-014b: Cloud Scheduler — `trigger-sync-article-embeddings`

**Purpose**: Periodic safety net that triggers the `sync-article-embeddings` Cloud Function daily to catch any missed syncs from the content CI/CD pipeline.

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Job name             | `trigger-sync-article-embeddings`                  |
| Schedule             | Daily at 04:00 UTC (`0 4 * * *`)                   |
| Target               | Cloud Function `sync-article-embeddings` (HTTP trigger) |
| HTTP method          | POST                                               |
| Authentication       | OIDC token (service account with `roles/cloudfunctions.invoker` and `roles/run.invoker`) |
| Region               | `asia-southeast1`                                  |
| Retry config         | Max 3 retries with exponential backoff             |

**Notes**:
- The function is idempotent — if all embeddings are already in sync (hash unchanged), the function exits quickly with no Gemini API calls.
- Running at 04:00 UTC minimizes overlap with peak traffic (asia-southeast1 timezone).
- This is the 3rd Cloud Scheduler job (alongside `trigger-sitemap-generation` and `trigger-cleanup-rate-limit-offenders`), within the free tier of 3 jobs.

---

#### INFRA-015: Cloud Storage — Terraform State Bucket

**Purpose**: Store Terraform remote state files for infrastructure-as-code management. This bucket is a **manually created bootstrap resource** — it is NOT managed by Terraform itself (chicken-and-egg: Terraform cannot manage the bucket that stores its own state).

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Bucket name          | `<project-id>-tfstate`                             |
| Region               | `asia-southeast1`                                  |
| Storage class        | Standard                                           |
| Versioning           | Enabled (allows state rollback)                    |
| Public access        | Not public (uniform bucket-level access)           |
| Lifecycle rules      | None (state files are small and versioned)         |
| Provisioning         | **Manual** (created by the project owner via Console or `gcloud`) |

**Access Control**:

| Principal                              | Role                           | Purpose                                    |
| -------------------------------------- | ------------------------------ | ------------------------------------------ |
| Terraform service account (SEC-012)    | `roles/storage.objectAdmin`   | Read/write state files and lock files      |

**Notes**:
- The bucket stores only Terraform state (`.tfstate`) and lock files. Expected size: < 1 MB.
- Versioning is critical for state recovery in case of corruption or accidental overwrites. GCS versioning keeps all prior versions of state files.
- The bucket name uses the convention `<project-id>-tfstate` for easy identification. Replace `<project-id>` with the actual project ID.
- No other service or user should have write access to this bucket to prevent state corruption.

---

#### INFRA-016: Terraform — Infrastructure as Code

**Purpose**: Manage GCP infrastructure resources declaratively using Terraform. Configuration files are stored in this repository; state is stored remotely in GCS (INFRA-015).

**Configuration**:

| Setting              | Value                                              |
| -------------------- | -------------------------------------------------- |
| Tool                 | Terraform (HashiCorp)                              |
| Config location      | This repository: `/terraform/` directory           |
| Remote backend       | GCS bucket `<project-id>-tfstate` (INFRA-015)      |
| State locking        | GCS-based (built-in with GCS backend)              |
| Service account      | `terraform-builder@<project-id>.iam.gserviceaccount.com` (SEC-012) |
| Provisioning (SA)    | **Manual** (service account created by the project owner) |

**Backend Configuration** (expected in `/terraform/backend.tf`):

```hcl
terraform {
  backend "gcs" {
    bucket = "<project-id>-tfstate"
    prefix = "terraform/state"
  }
}
```

**Scope of Terraform Management**:

Terraform manages GCP resources defined in the spec, including but not limited to:
- Cloud Run services (INFRA-003)
- Cloud Functions (INFRA-008a, 008c, 008d, INFRA-014)
- VPC and networking (INFRA-009)
- Cloud Armor security policies (INFRA-005)
- Cloud Load Balancer (INFRA-004)
- Cloud Scheduler jobs (INFRA-008b, INFRA-008d scheduler, INFRA-014b)
- BigQuery dataset and log sinks (INFRA-010)
- Firestore Native database (INFRA-012)
- IAM bindings and service accounts (except bootstrap resources)
- Cloud DNS (INFRA-006)

**Bootstrap Resources** (manually created, NOT managed by Terraform):

| Resource                       | Reason                                                   |
| ------------------------------ | -------------------------------------------------------- |
| GCP Project                    | Must exist before Terraform can run                      |
| Terraform state bucket (INFRA-015) | Cannot manage its own state storage                  |
| Terraform service account (SEC-012) | Must exist to authenticate Terraform operations     |
| Billing account link           | Pre-existing organizational resource                     |

**Notes**:
- Terraform configuration files will be added to this repository in a subsequent implementation phase. The current phase is documentation only.
- The `/terraform/` directory structure, module organization, and resource definitions are to be determined during implementation.
- State locking via GCS prevents concurrent Terraform runs from corrupting state.

---

#### INFRA-010: BigQuery Analytics Dataset & Log Sinks

**Purpose**: Route Cloud Logging logs to BigQuery for long-term storage, SQL-based analytics, and integration with Looker Studio dashboards.

**Dataset Configuration**:

| Setting              | Value                              |
| -------------------- | ---------------------------------- |
| Dataset name         | `website_logs`                     |
| Region               | `asia-southeast1`                  |
| Default table expiry | 730 days (2 years)                 |

**Log Sinks**:

Five Cloud Logging log sinks route logs to dedicated BigQuery tables within the `website_logs` dataset:

##### INFRA-010a: All Logs

| Setting          | Value                                              |
| ---------------- | -------------------------------------------------- |
| Sink name        | `sink-all-logs`                                    |
| Destination      | BigQuery table `website_logs.all_logs`              |
| Filter           | *(no filter — captures all project logs)*          |
| Purpose          | Complete log archive for ad-hoc SQL analysis       |

##### INFRA-010b: Cloud Armor & Load Balancer Logs

| Setting          | Value                                              |
| ---------------- | -------------------------------------------------- |
| Sink name        | `sink-cloud-armor-lb`                              |
| Destination      | BigQuery table `website_logs.cloud_armor_lb_logs`  |
| Filter           | `resource.type="http_load_balancer"`               |
| Table expiry     | **90 days** (overrides dataset default of 730 days) |
| Purpose          | WAF events, rate limiting analysis, DDoS investigation, security incident response |

> **Privacy Note**: Cloud Armor load balancer logs contain **full IP addresses** in the `httpRequest.remoteIp` field. These are generated by Google Cloud infrastructure at the load balancer level before requests reach the Go backend and cannot be truncated at the source. This table uses a 90-day retention period (shorter than the 2-year default) to limit the duration that full IPs are stored. Only the website owner has access to this table. Looker Studio dashboards SHALL NOT query this table for analytics reports — use `frontend_tracking_logs` (which contains truncated IPs) instead. This table is used solely for security investigations and DDoS analysis.

##### INFRA-010c: Frontend Error Logs

| Setting          | Value                                              |
| ---------------- | -------------------------------------------------- |
| Sink name        | `sink-frontend-errors`                             |
| Destination      | BigQuery table `website_logs.frontend_error_logs`  |
| Filter           | `resource.type="cloud_run_revision" AND jsonPayload.log_type="frontend_error"` |
| Purpose          | Client-side error trend analysis, browser/connection correlation |

**Note**: Requires the Go backend to emit a `log_type: "frontend_error"` field in structured log entries when processing `POST /t` requests with `action: "error_report"` (see OBS-001 in [07-observability-specifications.md](07-observability-specifications.md)).

##### INFRA-010d: Backend Error Logs

| Setting          | Value                                              |
| ---------------- | -------------------------------------------------- |
| Sink name        | `sink-backend-errors`                              |
| Destination      | BigQuery table `website_logs.backend_error_logs`   |
| Filter           | `resource.type="cloud_run_revision" AND severity>=ERROR AND NOT jsonPayload.log_type="frontend_error"` |
| Purpose          | Backend error trend analysis, masked 500 tracking  |

##### INFRA-010e: Frontend Tracking Logs

| Setting          | Value                                              |
| ---------------- | -------------------------------------------------- |
| Sink name        | `sink-frontend-tracking`                           |
| Destination      | BigQuery table `website_logs.frontend_tracking_logs` |
| Filter           | `resource.type="cloud_run_revision" AND jsonPayload.log_type="frontend_tracking"` |
| Purpose          | Visitor analytics — unique visitors, page views, referrer sources, browser distribution |

**Note**: Requires the Go backend to emit a `log_type: "frontend_tracking"` field in structured log entries when processing `POST /t` requests with `action: "page_view"` or other tracking actions (see OBS-001 in [07-observability-specifications.md](07-observability-specifications.md)).

**BigQuery Table Schema**:

- All tables use the [Cloud Logging BigQuery schema](https://cloud.google.com/logging/docs/export/bigquery) automatically generated by the log sink export.
- Key queryable fields in the auto-generated schema:
  - `timestamp` — log entry timestamp
  - `severity` — log severity level
  - `jsonPayload` — structured log data (RECORD type, fields vary by log entry)
  - `resource` — resource metadata (type, labels)
  - `httpRequest` — HTTP request details (for load balancer logs)

**Data Retention**:

- All tables in the `website_logs` dataset SHALL have a default table expiry of **730 days (2 years)**. Data older than 2 years is automatically deleted by BigQuery.
- This 2-year retention applies to 4 of the 5 tables. The `cloud_armor_lb_logs` table overrides this to 90 days (see INFRA-010b). No table retains data indefinitely.
- The retention period balances long-term trend analysis with privacy obligations and cost management.

**Data Anonymization in BigQuery**:

- IP addresses exported to BigQuery via Cloud Logging log sinks are the same values logged by the Go backend. The Go backend SHALL truncate IPv4 addresses (zero the last octet, e.g., `203.0.113.0`) and truncate IPv6 addresses (zero the last 80 bits) **before** writing log entries. This ensures that no full IP addresses are stored in BigQuery.
- User-Agent strings exported to BigQuery contain browser name and version only (as sent by the frontend in the `POST /t` request body). Raw `User-Agent` headers from `httpRequest` fields in load balancer logs (`cloud_armor_lb_logs`) are retained as-is since they do not contain personally identifiable information beyond general browser/OS info.
- No cookies, user accounts, session identifiers, or device fingerprints are present in any BigQuery table.
- The `frontend_tracking_logs` and `frontend_error_logs` tables contain only the structured fields emitted by the Go backend when processing `POST /t` requests (see OBS-001, OBS-002, OBS-003 in [07-observability-specifications.md](07-observability-specifications.md)).

**Summary of Data Stored in BigQuery**:

| Table                     | Personal Data Present                         | Anonymization Applied                  | Retention |
| ------------------------- | --------------------------------------------- | -------------------------------------- | --------- |
| `all_logs`                | Truncated IP addresses                        | IP last octet zeroed                   | 2 years   |
| `cloud_armor_lb_logs`     | **Full** IP, User-Agent (browser/OS info)     | No IP truncation (infrastructure-generated logs); 90-day retention | 90 days |
| `frontend_error_logs`     | Truncated IP, browser name/version            | IP last octet zeroed                   | 2 years   |
| `backend_error_logs`      | Truncated IP (in request context)             | IP last octet zeroed                   | 2 years   |
| `frontend_tracking_logs`  | Truncated IP, browser, referrer, page visited | IP last octet zeroed                   | 2 years   |

**Notes**:
- Log sinks operate independently of the existing Cloud Logging log buckets and the rate-limit log sink (INFRA-008c). They do not interfere with each other.
- BigQuery tables are partitioned by ingestion time automatically when created by log sinks.
- The 2-year table expiry is set at the dataset level as the default. Individual tables inherit this expiry unless explicitly overridden. Only the `cloud_armor_lb_logs` table overrides this default to 90 days for privacy reasons (see INFRA-010b).

---

#### INFRA-011: Looker Studio Integration

**Purpose**: Provide owner-operated analytics dashboards using Looker Studio connected to the BigQuery `website_logs` dataset.

**Service Account Configuration**:

| Setting                    | Value                                              |
| -------------------------- | -------------------------------------------------- |
| Service account name       | `looker-studio-reader`                             |
| Service account email      | `looker-studio-reader@<project-id>.iam.gserviceaccount.com` |
| BigQuery role (dataset)    | `roles/bigquery.dataViewer` on `website_logs` dataset |
| BigQuery role (project)    | `roles/bigquery.jobUser` on project (required to run queries) |
| Key type                   | Service account key (JSON) for Looker Studio data connector |

**Looker Studio Configuration**:

| Setting                    | Value                                              |
| -------------------------- | -------------------------------------------------- |
| Data source type           | BigQuery connector                                 |
| Authentication             | Service account (JSON key)                         |
| Tables connected           | All 5 tables in `website_logs` dataset             |
| Refresh schedule           | Automatic (Looker Studio default)                  |

**Analytics Capabilities**:

The following analytics are enabled by the BigQuery data via Looker Studio:

| Metric / Report              | Source Table                    | Description                                    |
| ---------------------------- | ------------------------------- | ---------------------------------------------- |
| Unique visitors              | `frontend_tracking_logs`        | Distinct IP addresses per time period          |
| Page views over time         | `frontend_tracking_logs`        | Total and per-page view counts                 |
| Top pages by visits          | `frontend_tracking_logs`        | Most visited pages ranked                      |
| Referrer sources             | `frontend_tracking_logs`        | Traffic sources breakdown                      |
| Browser distribution         | `frontend_tracking_logs`        | Browser name/version breakdown                 |
| Geographic distribution      | `frontend_tracking_logs`        | Visitor locations derived from IP              |
| Connection speed analysis    | `frontend_tracking_logs`        | Visitor connection quality breakdown           |
| Frontend error trends        | `frontend_error_logs`           | Error frequency, types, and affected pages     |
| Error-browser correlation    | `frontend_error_logs`           | Errors grouped by browser/connection speed     |
| Backend error trends         | `backend_error_logs`            | Backend error frequency and types              |
| Masked 500 tracking          | `backend_error_logs`            | Internal errors masked as 404                  |
| Cloud Armor activity         | `cloud_armor_lb_logs`           | Rate limit blocks, WAF events over time        |
| Traffic patterns             | `cloud_armor_lb_logs`           | Request volume, geographic distribution        |
| Request latency analysis     | `all_logs`                      | API latency percentiles from structured logs   |

**Notes**:
- Looker Studio is owned and operated by the website owner. No public access.
- The service account has read-only access — it cannot modify or delete data.
- Looker Studio queries against BigQuery may incur costs based on the amount of data scanned. Use partitioned tables and targeted queries to minimize costs.

---

### Network Diagram

```
                    Internet
                       │
                       ▼
              ┌─────────────────┐
              │   Cloud DNS     │
              │  tjmonsi.com    │
              │ api.tjmonsi.com │
              └────────┬────────┘
                       │
                       ▼
              ┌─────────────────┐
              │  Cloud Armor    │
              │  (WAF / DDoS)   │
              └────────┬────────┘
                       │
                       ▼
              ┌─────────────────┐
              │  Cloud Load     │
              │  Balancer (L7)  │
              └───┬─────────┬───┘
                  │         │
        ┌─────────┘         └─────────┐
        ▼                             ▼
┌───────────────┐       ┌──── VPC (Production only) ────┐
│   Firebase    │       │                                │
│   Hosting +   │       │  ┌───────────────┐             │
│   Functions   │       │  │   Cloud Run   │             │
│   (SPA)       │       │  │   (Go API)    │             │
│               │       │  │   0-N inst.   │             │
│  Rewrites:    │       │  └───────┬───────┘             │
│  /sitemap.xml─│───────│──────────┘                     │
└───────────────┘       │          │                      │
                        │          ▼                      │
                        │  ┌───────────────┐             │
                        │  │   Firestore   │             │
                        │  │   Enterprise  │             │
                        │  │   asia-se1    │             │
                        │  └───────┬───────┘             │
                        │          ▲                      │
                        │  ┌───────┴───────┐             │
Cloud Scheduler ───────▶│  │Cloud Function │             │
                        │  │(Sitemap Gen)  │             │
                        │  └───────────────┘             │
                        │                                │
                        │  ┌───────────────┐             │
Cloud Armor Log Sink ──▶│  │Cloud Function │             │
                        │  │(Log Proc.)    │             │
                        │  └───────────────┘             │
                        │                                │
                        │  ┌───────────────┐             │
Cloud Scheduler ───────▶│  │Cloud Function │             │
                        │  │(Cleanup)      │             │
                        │  └───────────────┘             │
                        │                                │
                        │  ┌───────────────┐             │
Content CI/CD (WIF) ───▶│  │Cloud Function │             │
Cloud Scheduler ───────▶│  │(Embed Sync)   │             │
                        │  │(daily safety) │             │
                        │  └───────┬───────┘             │
                        └──────────│─────────────────────┘
                                   │
                        ┌──────────▼─────────────────────┐
                        │   Firestore Native Mode        │
                        │   (Vector Search)              │
                        │   asia-southeast1              │
                        └────────────────────────────────┘
                                   ▲
                        Cloud Run + Embed Sync
                        query/write vectors
                        ┌────────────────────────────────┐
                        │   Vertex AI (Gemini)           │
                        │   gemini-embedding-001          │
                        └────────────────────────────────┘
                                   ▲
                        Cloud Run + Embed Sync
                        call for embeddings

              Cloud Logging (receives all service logs)
                           │
                           ▼ (5 Log Sinks)
              ┌──────────────────────────────────┐
              │           BigQuery               │
              │    Dataset: website_logs          │
              │                                  │
              │  • all_logs                      │
              │  • cloud_armor_lb_logs           │
              │  • frontend_error_logs           │
              │  • backend_error_logs            │
              │  • frontend_tracking_logs        │
              └────────────┬─────────────────────┘
                           │ (Service Account)
                           ▼
              ┌──────────────────────────────────┐
              │        Looker Studio             │
              │   (Owner-operated analytics)     │
              └──────────────────────────────────┘

              ┌──────────────────────────────────┐
              │   Terraform (IaC)                │
              │   Configs in /terraform/         │
              │   SA: terraform-builder@         │
              │      <project-id>                │
              └────────────┬─────────────────────┘
                           │ (remote state)
                           ▼
              ┌──────────────────────────────────┐
              │   Cloud Storage                  │
              │   <project-id>-tfstate           │
              │   (manually created)             │
              └──────────────────────────────────┘
```
